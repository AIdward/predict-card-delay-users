{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T14:19:04.768742Z",
     "start_time": "2021-05-16T14:19:04.763728Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import glob\n",
    "import os\n",
    "import joblib\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import combinations\n",
    "\n",
    "from hyperopt.pyll.base import scope\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "from catboost import Pool, CatBoostClassifier\n",
    "from kaggler.model import AutoLGB\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, GridSearchCV, StratifiedShuffleSplit, train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, log_loss\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 문제 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 데이터 수집"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) 데이콘 기본 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T14:19:07.139657Z",
     "start_time": "2021-05-16T14:19:07.048901Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv').drop(['index'], axis=1).fillna('NAN')\n",
    "test = pd.read_csv('data/test.csv').drop(['index'], axis=1).fillna('NAN')\n",
    "sample_submission = pd.read_csv('data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 탐색적 데이터 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 변수 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T14:19:10.208824Z",
     "start_time": "2021-05-16T14:19:10.096988Z"
    }
   },
   "outputs": [],
   "source": [
    "# train데이터와 test데이터 변수를 함께 조정하기 위해 병합\n",
    "merge_data = pd.concat([train, test], axis = 0)\n",
    "\n",
    "# DAYS_BIRTH\n",
    "merge_data['DAYS_BIRTH_month']=np.floor((-merge_data['DAYS_BIRTH'])/30)-(\n",
    "    (np.floor((-merge_data['DAYS_BIRTH'])/30)/12).astype(int)*12)\n",
    "merge_data['DAYS_BIRTH_week']=np.floor((-merge_data['DAYS_BIRTH'])/7)-(\n",
    "    (np.floor((-merge_data['DAYS_BIRTH'])/7)/4).astype(int)*4)\n",
    "\n",
    "# DAYS_EMPLOYED\n",
    "merge_data['DAYS_EMPLOYED_month']=np.floor((-merge_data['DAYS_EMPLOYED'])/30)-(\n",
    "    (np.floor((-merge_data['DAYS_EMPLOYED'])/30)/12).astype(int)*12)\n",
    "merge_data['DAYS_EMPLOYED_week']=np.floor((-merge_data['DAYS_EMPLOYED'])/7)-(\n",
    "    (np.floor((-merge_data['DAYS_EMPLOYED'])/7)/4).astype(int)*4)\n",
    "\n",
    "# before_EMPLOYED\n",
    "merge_data['before_EMPLOYED']=merge_data['DAYS_BIRTH']-merge_data['DAYS_EMPLOYED']\n",
    "merge_data['before_EMPLOYED_month']=np.floor((-merge_data['before_EMPLOYED'])/30)-(\n",
    "    (np.floor((-merge_data['before_EMPLOYED'])/30)/12).astype(int)*12)\n",
    "merge_data['before_EMPLOYED_week']=np.floor((-merge_data['before_EMPLOYED'])/7)-(\n",
    "    (np.floor((-merge_data['before_EMPLOYED'])/7)/4).astype(int)*4)\n",
    "\n",
    "# DAYS_BIRTH\n",
    "merge_data['1new_1'] = merge_data['DAYS_BIRTH_month'] / merge_data['income_total']\n",
    "merge_data['2new_1'] = merge_data['DAYS_BIRTH_week'] / merge_data['income_total']\n",
    "\n",
    "# DAYS_EMPLOYED\n",
    "merge_data['10new_1'] = merge_data['DAYS_EMPLOYED_month'] / merge_data['income_total']\n",
    "merge_data['11new_1'] = merge_data['DAYS_EMPLOYED_week'] / merge_data['income_total']\n",
    "\n",
    "# before_EMPLOYED\n",
    "merge_data['12new_1'] = merge_data['before_EMPLOYED'] / merge_data['income_total']\n",
    "merge_data['13new_1'] = merge_data['before_EMPLOYED_month'] / merge_data['income_total']\n",
    "merge_data['14new_1'] = merge_data['before_EMPLOYED_week'] / merge_data['income_total']\n",
    "\n",
    "# 총 수익을 가족 수로 나누기\n",
    "merge_data['15new_1'] = merge_data['income_total'] / merge_data['family_size']\n",
    "\n",
    "# 융합 삭제\n",
    "#merge_data['3new_1'] = merge_data['DAYS_EMPLOYED_month'] / merge_data['DAYS_BIRTH_month']\n",
    "#merge_data['4new_1'] = merge_data['DAYS_EMPLOYED_month'] / merge_data['DAYS_BIRTH_week']\n",
    "#merge_data['5new_1'] = merge_data['DAYS_EMPLOYED_week'] / merge_data['DAYS_BIRTH_month']\n",
    "#merge_data['6new_1'] = merge_data['DAYS_EMPLOYED_week'] / merge_data['DAYS_BIRTH_week']\n",
    "\n",
    "#merge_data['7new_1'] =  merge_data['begin_month'] / merge_data['DAYS_BIRTH_month']\n",
    "#merge_data['8new_1'] =  merge_data['begin_month'] / merge_data['DAYS_EMPLOYED_month']\n",
    "#merge_data['9new_1'] =  merge_data['begin_month'] / merge_data['before_EMPLOYED_month']\n",
    "\n",
    "merge_data['new_1'] = merge_data['child_num'] / merge_data['income_total']\n",
    "merge_data['new_2'] = merge_data['family_size'] / merge_data['income_total']\n",
    "merge_data['new_3'] = merge_data['DAYS_BIRTH'] / merge_data['income_total']\n",
    "merge_data['new_4'] = merge_data['DAYS_EMPLOYED'] / merge_data['income_total']\n",
    "#merge_data['new_5'] = merge_data['begin_month'] / merge_data['income_total']\n",
    "merge_data['new_6'] =  merge_data['DAYS_EMPLOYED'] / merge_data['DAYS_BIRTH']\n",
    "\n",
    "# 소득 skewed-data 처리\n",
    "merge_data['log1p_income_total'] = np.log1p(merge_data['income_total'])\n",
    "#merge_data['log_income_total'] = np.log(merge_data['income_total'])\n",
    "#merge_data['sqrt_income_total'] = np.sqrt(merge_data['income_total'])\n",
    "#merge_data['boxcox_income_total'] = stats.boxcox(merge_data['income_total'])[0]\n",
    "\n",
    "merge_data = merge_data.fillna(-999)\n",
    "train = merge_data[merge_data['credit'] != -999]\n",
    "test = merge_data[merge_data['credit'] == -999]\n",
    "test.drop('credit', axis = 1, inplace = True)\n",
    "\n",
    "train_cols = list(train.columns); train_cols.remove('credit'); train_cols.append('credit')\n",
    "train = train[train_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "train = train[train['child_num']<=6].reset_index(drop=True) # 아이의 수가 7명 이상인 데이터 제거"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T14:19:16.500312Z",
     "start_time": "2021-05-16T14:19:16.484356Z"
    }
   },
   "outputs": [],
   "source": [
    "train_oh = train.copy()\n",
    "train_noh = train.copy()\n",
    "test_oh = test.copy()\n",
    "test_noh = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T14:19:17.214478Z",
     "start_time": "2021-05-16T14:19:17.179479Z"
    }
   },
   "outputs": [],
   "source": [
    "object_col = []\n",
    "for col in train_noh.columns:\n",
    "    if train_noh[col].dtype == 'object':\n",
    "        train_noh[col] = train_noh[col].astype('category')\n",
    "        test_noh[col] = test_noh[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T14:19:18.183114Z",
     "start_time": "2021-05-16T14:19:18.095368Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gender', 'car', 'reality', 'income_type', 'edu_type', 'family_type', 'house_type', 'occyp_type']\n"
     ]
    }
   ],
   "source": [
    "object_col = []\n",
    "for col in train_oh.columns:\n",
    "    if train_oh[col].dtype == 'object':\n",
    "        object_col.append(col)\n",
    "print(object_col)        \n",
    "enc = OneHotEncoder()\n",
    "enc.fit(train.loc[:,object_col])\n",
    "\n",
    "\n",
    "train_onehot_df = pd.DataFrame(enc.transform(train_oh.loc[:,object_col]).toarray(), \n",
    "             columns=enc.get_feature_names(object_col))\n",
    "train_oh.drop(object_col, axis=1, inplace=True)\n",
    "train_oh = pd.concat([train_oh, train_onehot_df], axis=1)    \n",
    "\n",
    "test_onehot_df = pd.DataFrame(enc.transform(test_oh.loc[:,object_col]).toarray(), \n",
    "             columns=enc.get_feature_names(object_col))\n",
    "test_oh.drop(object_col, axis=1, inplace=True)\n",
    "test_oh = pd.concat([test_oh, test_onehot_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature 하나씩 빼면서 성능 체크"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "변수 하나씩 제거하면서 성능 체크<br>\n",
    "제거하여 성능이 좋게 나온 것들은 리스트에 따로 저장해두기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T14:19:19.848493Z",
     "start_time": "2021-05-16T14:19:19.839497Z"
    }
   },
   "outputs": [],
   "source": [
    "train_x = train_noh.drop(['credit'], axis=1)\n",
    "train_y = train_noh['credit']\n",
    "test_x = test_noh.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T14:21:22.076127Z",
     "start_time": "2021-05-16T14:19:21.464762Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial_multi_logloss: 0.7085975312773732\n",
      "(0,) multi_logloss: 0.7092004858142139\n",
      "(1,) multi_logloss: 0.7082538895419418\n",
      "(2,) multi_logloss: 0.708226883651835\n",
      "(3,) multi_logloss: 0.7094788922932076\n",
      "(4,) multi_logloss: 0.7085895398370279\n",
      "(5,) multi_logloss: 0.7089115398868129\n",
      "(6,) multi_logloss: 0.7099398346344317\n",
      "(7,) multi_logloss: 0.7113719335263833\n",
      "(8,) multi_logloss: 0.7093174067325209\n",
      "(9,) multi_logloss: 0.7097997375662474\n",
      "(10,) multi_logloss: 0.7094373639226383\n",
      "(11,) multi_logloss: 0.7085975312773732\n",
      "(12,) multi_logloss: 0.7094023832694786\n",
      "(13,) multi_logloss: 0.7106701457524007\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-10a5dc5c2b5b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[0mlgbm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLGBMClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobjective\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'multiclass'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m             \u001b[0mlgbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m             \u001b[0mcv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlgbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'{j} multi_logloss: {log_loss(train_y, cv)}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m    845\u001b[0m                     \u001b[0mvalid_sets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mvalid_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_le\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    846\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 847\u001b[1;33m         super(LGBMClassifier, self).fit(X, _y, sample_weight=sample_weight,\n\u001b[0m\u001b[0;32m    848\u001b[0m                                         \u001b[0minit_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minit_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalid_sets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    849\u001b[0m                                         \u001b[0meval_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m    610\u001b[0m             \u001b[0minit_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbooster_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 612\u001b[1;33m         self._Booster = train(params, train_set,\n\u001b[0m\u001b[0;32m    613\u001b[0m                               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_sets\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalid_sets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m                               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    250\u001b[0m                                     evaluation_result_list=None))\n\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m         \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   2456\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__set_objective_to_none\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2457\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Cannot update due to null objective function.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2458\u001b[1;33m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0m\u001b[0;32m   2459\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2460\u001b[0m                 ctypes.byref(is_finished)))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "cv = np.zeros((train_x.shape[0], 3))\n",
    "for n, (train_idx, val_idx) in enumerate(kfold.split(train_x, train_y)):\n",
    "    x_train, x_val = train_x.iloc[train_idx], train_x.iloc[val_idx]\n",
    "    y_train, y_val = train_y.iloc[train_idx], train_y.iloc[val_idx]\n",
    "    lgbm = LGBMClassifier(n_estimators=1000, objective='multiclass')\n",
    "    lgbm.fit(x_train, y_train, eval_set=[(x_val, y_val)], early_stopping_rounds=30, verbose=None)\n",
    "    cv[val_idx] = lgbm.predict_proba(x_val)\n",
    "print(f'Initial_multi_logloss: {log_loss(train_y, cv)}')\n",
    "remove_features = []\n",
    "for i in range(1, 2):\n",
    "    for j in combinations(list(range(0, train_x.shape[1])), i):\n",
    "        train_new_x = train_x.drop(train_x.columns[list(j)], axis=1)\n",
    "        \n",
    "        kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "        cv = np.zeros((train_new_x.shape[0], 3))\n",
    "        for n, (train_idx, val_idx) in enumerate(kfold.split(train_new_x, train_y)):\n",
    "            x_train, x_val = train_new_x.iloc[train_idx], train_new_x.iloc[val_idx]\n",
    "            y_train, y_val = train_y.iloc[train_idx], train_y.iloc[val_idx]\n",
    "            lgbm = LGBMClassifier(n_estimators=1000, objective='multiclass')\n",
    "            lgbm.fit(x_train, y_train, eval_set=[(x_val, y_val)], early_stopping_rounds=30, verbose=None)\n",
    "            cv[val_idx] = lgbm.predict_proba(x_val)\n",
    "        print(f'{j} multi_logloss: {log_loss(train_y, cv)}')\n",
    "        if log_loss(train_y, cv)<0.708:\n",
    "            remove_features.append(list(j)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 저장한 변수 지우는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T14:21:32.639353Z",
     "start_time": "2021-05-16T14:21:32.628383Z"
    }
   },
   "outputs": [],
   "source": [
    "remove_features = [1, 3, 4, 8, 11, 32]\n",
    "train = train.drop(train.columns[remove_features], axis=1)\n",
    "test = test.drop(test.columns[remove_features], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 다시 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T14:21:33.922697Z",
     "start_time": "2021-05-16T14:21:33.909733Z"
    }
   },
   "outputs": [],
   "source": [
    "train_oh = train.copy()\n",
    "train_noh = train.copy()\n",
    "test_oh = test.copy()\n",
    "test_noh = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T14:21:34.699235Z",
     "start_time": "2021-05-16T14:21:34.676317Z"
    }
   },
   "outputs": [],
   "source": [
    "object_col = []\n",
    "for col in train_noh.columns:\n",
    "    if train_noh[col].dtype == 'object':\n",
    "        train_noh[col] = train_noh[col].astype('category')\n",
    "        test_noh[col] = test_noh[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T14:21:35.588036Z",
     "start_time": "2021-05-16T14:21:35.519188Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gender', 'reality', 'income_type', 'edu_type', 'family_type', 'occyp_type']\n"
     ]
    }
   ],
   "source": [
    "object_col = []\n",
    "for col in train_oh.columns:\n",
    "    if train_oh[col].dtype == 'object':\n",
    "        object_col.append(col)\n",
    "print(object_col)        \n",
    "enc = OneHotEncoder()\n",
    "enc.fit(train.loc[:,object_col])\n",
    "\n",
    "\n",
    "train_onehot_df = pd.DataFrame(enc.transform(train_oh.loc[:,object_col]).toarray(), \n",
    "             columns=enc.get_feature_names(object_col))\n",
    "train_oh.drop(object_col, axis=1, inplace=True)\n",
    "train_oh = pd.concat([train_oh, train_onehot_df], axis=1)    \n",
    "\n",
    "test_onehot_df = pd.DataFrame(enc.transform(test_oh.loc[:,object_col]).toarray(), \n",
    "             columns=enc.get_feature_names(object_col))\n",
    "test_oh.drop(object_col, axis=1, inplace=True)\n",
    "test_oh = pd.concat([test_oh, test_onehot_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T14:21:37.019941Z",
     "start_time": "2021-05-16T14:21:37.015925Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_dict = {}\n",
    "pred_test_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T14:21:38.271151Z",
     "start_time": "2021-05-16T14:21:38.262176Z"
    }
   },
   "outputs": [],
   "source": [
    "train_x = train_noh.drop(['credit'], axis=1)\n",
    "train_y = train_noh['credit']\n",
    "test_x = test_noh.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T14:22:24.504454Z",
     "start_time": "2021-05-16T14:22:24.359825Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with params:                                                                                                  \n",
      "{'colsample_bytree': 0.45, 'device': 'gpu', 'learning_rate': 0.004, 'max_depth': -1, 'min_child_weight': 2, 'n_estimators': 5000, 'num_class': 3, 'num_leaves': 1000, 'objective': 'multiclass', 'seed': 42, 'subsample': 1}\n",
      "  0%|                                                                           | 0/12 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                           | 0/12 [00:00<?, ?trial/s, best loss=?]\n"
     ]
    },
    {
     "ename": "LightGBMError",
     "evalue": "GPU Tree Learner was not enabled in this build.\nPlease recompile with CMake option -DUSE_GPU=1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLightGBMError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-2addaa68ba0c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mbest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m \u001b[0mbest_hyperparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The best hyperparameters are: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_hyperparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-23-2addaa68ba0c>\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(random_state)\u001b[0m\n\u001b[0;32m     48\u001b[0m     }\n\u001b[0;32m     49\u001b[0m     \u001b[1;31m# Use the fmin function from Hyperopt to find the best hyperparameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m     best = fmin(score, space, algo=tpe.suggest, \n\u001b[0m\u001b[0;32m     51\u001b[0m                 \u001b[1;31m# trials=trials,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m                 max_evals=12)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    551\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m     \u001b[1;31m# next line is where the fmin is actually executed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 553\u001b[1;33m     \u001b[0mrval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    354\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 356\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    357\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, N, block_until_done)\u001b[0m\n\u001b[0;32m    290\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m                     \u001b[1;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[1;34m(self, N)\u001b[0m\n\u001b[0;32m    168\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    171\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"job exception: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\hyperopt\\base.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[0;32m    905\u001b[0m                 \u001b[0mprint_node_on_error\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrec_eval_print_node_on_error\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    906\u001b[0m             )\n\u001b[1;32m--> 907\u001b[1;33m             \u001b[0mrval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    908\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-23-2addaa68ba0c>\u001b[0m in \u001b[0;36mscore\u001b[1;34m(params)\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mlgbmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLGBMClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mlgbmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0mcv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlgbmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'fold{n+1} multi_logloss: {log_loss(y_val, cv[val_idx, :])}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m    845\u001b[0m                     \u001b[0mvalid_sets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mvalid_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_le\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    846\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 847\u001b[1;33m         super(LGBMClassifier, self).fit(X, _y, sample_weight=sample_weight,\n\u001b[0m\u001b[0;32m    848\u001b[0m                                         \u001b[0minit_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minit_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalid_sets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    849\u001b[0m                                         \u001b[0meval_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m    610\u001b[0m             \u001b[0minit_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbooster_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 612\u001b[1;33m         self._Booster = train(params, train_set,\n\u001b[0m\u001b[0;32m    613\u001b[0m                               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_sets\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalid_sets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m                               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    229\u001b[0m     \u001b[1;31m# construct booster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 231\u001b[1;33m         \u001b[0mbooster\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBooster\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    232\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_valid_contain_train\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m             \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_train_data_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, params, train_set, model_file, model_str, silent)\u001b[0m\n\u001b[0;32m   2056\u001b[0m             \u001b[0mparams_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparam_dict_to_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2057\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2058\u001b[1;33m             _safe_call(_LIB.LGBM_BoosterCreate(\n\u001b[0m\u001b[0;32m   2059\u001b[0m                 \u001b[0mtrain_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2060\u001b[0m                 \u001b[0mc_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m_safe_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \"\"\"\n\u001b[0;32m     54\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecode_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLGBM_GetLastError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLightGBMError\u001b[0m: GPU Tree Learner was not enabled in this build.\nPlease recompile with CMake option -DUSE_GPU=1"
     ]
    }
   ],
   "source": [
    "SEED=42\n",
    "\n",
    "# Hyperopt의 metric함수를 StratifiedKFold(cv=5)로 구하기\n",
    "def score(params):\n",
    "    print(\"Training with params: \")\n",
    "    print(params)\n",
    "    \n",
    "    kfold = StratifiedKFold(n_splits=5, random_state = SEED, shuffle = True)\n",
    "    cv = np.zeros((train_x.shape[0], 3))\n",
    "\n",
    "    for n, (train_idx, val_idx) in enumerate(kfold.split(train_x, train_y)):\n",
    "        \n",
    "        x_train, x_val = train_x.iloc[train_idx], train_x.iloc[val_idx]\n",
    "        y_train, y_val = train_y.iloc[train_idx], train_y.iloc[val_idx]\n",
    "\n",
    "        lgbmodel = LGBMClassifier(**params)\n",
    "\n",
    "        lgbmodel.fit(x_train, y_train, eval_set=[(x_val, y_val)], early_stopping_rounds=30, verbose=100) \n",
    "        cv[val_idx, :] = lgbmodel.predict_proba(x_val)\n",
    "        print(f'fold{n+1} multi_logloss: {log_loss(y_val, cv[val_idx, :])}')\n",
    "    print('multi_logloss:', log_loss(train_y, cv))\n",
    "    score = log_loss(train_y, cv)\n",
    "    return {'loss': score, 'status': STATUS_OK}\n",
    "\n",
    "# Hyperopt의 범위를 지정해주고 max_evals만큼 반복한 후 최적의 파라미터를 반환\n",
    "def optimize(random_state=SEED):\n",
    "    \n",
    "#     param = {'objective':'multi:softprob', 'seed':SEED, 'num_class': 3, 'eval_metric':'mlogloss', \n",
    "#          'eta': 0.01, 'min_child_weight': 3,\n",
    "#          'colsample_bytree': 0.3, 'colsample_bylevel': 0.6, 'subsample': 0.8\n",
    "#         }\n",
    "    space = {\n",
    "        'learning_rate': hp.quniform('learning_rate', 0.003, 0.006, 0.001),\n",
    "        #'learning_rate' : 0.005,\n",
    "        'num_leaves': scope.int(hp.quniform('num_leaves', 1000, 1200, 50)),\n",
    "        'num_leaves' : 1000,\n",
    "        #'min_child_weight': hp.quniform('min_child_weight', 1, 3, 1),\n",
    "        'min_child_weight' : 2,\n",
    "        #'subsample': hp.quniform('subsample', 0.8, 1, 0.05),\n",
    "        'subsample' : 1,\n",
    "        'colsample_bytree': hp.quniform('colsample_bytree', 0.3, 0.7, 0.05),\n",
    "        #'colsample_bytree' : 0.4,\n",
    "        'max_depth' : -1,\n",
    "        'n_estimators' : 5000,\n",
    "        'objective' : 'multiclass',\n",
    "        'num_class' : 3,\n",
    "        'seed': SEED,\n",
    "    }\n",
    "    # Use the fmin function from Hyperopt to find the best hyperparameters\n",
    "    best = fmin(score, space, algo=tpe.suggest, \n",
    "                # trials=trials, \n",
    "                max_evals=12)\n",
    "    return best\n",
    "\n",
    "best_hyperparams = optimize()\n",
    "print(\"The best hyperparameters are: \", \"\\n\")\n",
    "print(best_hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 seeds x 5 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lucky_seeds=[42,2019,91373] # Lucky seed 늘려가면서 하기\n",
    "for i, seed in enumerate(lucky_seeds):\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=10, random_state = seed, shuffle = True) # CV 늘려가면서 하기\n",
    "    cv=np.zeros((train_x.shape[0], 3))\n",
    "    pred_test = np.zeros((test_x.shape[0], 3), dtype=float)\n",
    "    \n",
    "    for n, (train_idx, val_idx) in enumerate(kfold.split(train_x, train_y)):\n",
    "\n",
    "        x_train, x_val = train_x.iloc[train_idx], train_x.iloc[val_idx]\n",
    "        y_train, y_val = train_y.iloc[train_idx], train_y.iloc[val_idx]\n",
    "        \n",
    "        lgbmodel = LGBMClassifier(learning_rate=0.005, objective='multiclass', n_estimators=10000, num_leaves=1000, \n",
    "                                  max_depth=-1, min_child_weight=2, colsample_bytree=0.55,  \n",
    "                                   n_jobs=-1, random_state=seed)\n",
    "\n",
    "        lgbmodel.fit(x_train, y_train, eval_set=[(x_val, y_val)], early_stopping_rounds=30, verbose=100) \n",
    "        #joblib.dump(lgbmodel, f'./pred_pkl/LGB_{n+1}_fold_{seed}_seed_lgb.pkl')\n",
    "\n",
    "        # CROSS-VALIDATION , EVALUATE CV\n",
    "        cv[val_idx,:] = lgbmodel.predict_proba(x_val)\n",
    "        pred_test += lgbmodel.predict_proba(test_x) / 10 # CV 바꾸면 이 숫자도 똑같이 바꿔야함\n",
    "    pred_dict['lgb'+str(i+1)] = cv\n",
    "    pred_test_dict['lgb'+str(i+1)] = pred_test\n",
    "        \n",
    "    print('multi_logloss :', log_loss(train_y, cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lgbmodels_path = os.listdir('./pred_pkl/')\n",
    "lgbmodels_list = [x for x in lgbmodels_path if x.endswith(\"lgb.pkl\")]\n",
    "assert len(lgbmodels_list) == 15\n",
    "lgb_preds = np.zeros((test_x.shape[0], 3))\n",
    "\n",
    "for m in lgbmodels_list:\n",
    "    lgbmodel = joblib.load('./pred_pkl/'+m)\n",
    "    lgb_preds_proba = lgbmodel.predict_proba(test)\n",
    "    lgb_preds += lgb_preds_proba/15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "원핫인코딩된 feature로 만들어주기 **꼭 밑에 코드 실행하고 XGBoost랑 Randomforest 돌리기!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T14:23:34.456443Z",
     "start_time": "2021-05-16T14:23:34.423450Z"
    }
   },
   "outputs": [],
   "source": [
    "train_x = train_oh.drop(['credit'], axis=1)\n",
    "train_y = train_oh['credit']\n",
    "test_x = test_oh.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Tuning (hyperopt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이거 오래걸리므로 안해도됨, 그리고 이미 했음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T17:07:47.991165Z",
     "start_time": "2021-05-16T14:45:57.913381Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with params:                                                                                                  \n",
      "{'colsample_bylevel': 0.4, 'colsample_bytree': 0.45, 'eta': 0.005, 'eval_metric': 'mlogloss', 'gamma': 0.7000000000000001, 'max_depth': 100, 'min_child_weight': 3.0, 'num_class': 3, 'objective': 'multi:softprob', 'seed': 0, 'subsample': 0.65}\n",
      "[0]\ttrain-mlogloss:1.09557\tvalid-mlogloss:1.09625                                                                      \n",
      "[100]\ttrain-mlogloss:0.86682\tvalid-mlogloss:0.92535                                                                    \n",
      "[200]\ttrain-mlogloss:0.72647\tvalid-mlogloss:0.83143                                                                    \n",
      "[300]\ttrain-mlogloss:0.63386\tvalid-mlogloss:0.77778                                                                    \n",
      "[400]\ttrain-mlogloss:0.56850\tvalid-mlogloss:0.74619                                                                    \n",
      "[500]\ttrain-mlogloss:0.52076\tvalid-mlogloss:0.72756                                                                    \n",
      "[600]\ttrain-mlogloss:0.48293\tvalid-mlogloss:0.71610                                                                    \n",
      "[700]\ttrain-mlogloss:0.45345\tvalid-mlogloss:0.70926                                                                    \n",
      "[800]\ttrain-mlogloss:0.42866\tvalid-mlogloss:0.70524                                                                    \n",
      "[900]\ttrain-mlogloss:0.40788\tvalid-mlogloss:0.70332                                                                    \n",
      "[1000]\ttrain-mlogloss:0.39058\tvalid-mlogloss:0.70248                                                                   \n",
      "[1074]\ttrain-mlogloss:0.37911\tvalid-mlogloss:0.70240                                                                   \n",
      "fold1 multi_logloss: 0.7023985431930806                                                                                \n",
      "[0]\ttrain-mlogloss:1.09561\tvalid-mlogloss:1.09624                                                                      \n",
      "[100]\ttrain-mlogloss:0.86898\tvalid-mlogloss:0.92030                                                                    \n",
      "[200]\ttrain-mlogloss:0.72974\tvalid-mlogloss:0.82297                                                                    \n",
      "[300]\ttrain-mlogloss:0.63756\tvalid-mlogloss:0.76634                                                                    \n",
      "[400]\ttrain-mlogloss:0.57218\tvalid-mlogloss:0.73270                                                                    \n",
      "[500]\ttrain-mlogloss:0.52409\tvalid-mlogloss:0.71257                                                                    \n",
      "[600]\ttrain-mlogloss:0.48600\tvalid-mlogloss:0.70033                                                                    \n",
      "[700]\ttrain-mlogloss:0.45629\tvalid-mlogloss:0.69288                                                                    \n",
      "[800]\ttrain-mlogloss:0.43121\tvalid-mlogloss:0.68851                                                                    \n",
      "[900]\ttrain-mlogloss:0.41052\tvalid-mlogloss:0.68622                                                                    \n",
      "[1000]\ttrain-mlogloss:0.39309\tvalid-mlogloss:0.68503                                                                   \n",
      "[1100]\ttrain-mlogloss:0.37772\tvalid-mlogloss:0.68489                                                                   \n",
      "[1111]\ttrain-mlogloss:0.37623\tvalid-mlogloss:0.68494                                                                   \n",
      "fold2 multi_logloss: 0.6849408274036146                                                                                \n",
      "[0]\ttrain-mlogloss:1.09583\tvalid-mlogloss:1.09641                                                                      \n",
      "[100]\ttrain-mlogloss:0.86742\tvalid-mlogloss:0.91981                                                                    \n",
      "[200]\ttrain-mlogloss:0.72957\tvalid-mlogloss:0.82341                                                                    \n",
      "[300]\ttrain-mlogloss:0.63771\tvalid-mlogloss:0.76662                                                                    \n",
      "[400]\ttrain-mlogloss:0.57202\tvalid-mlogloss:0.73166                                                                    \n",
      "[500]\ttrain-mlogloss:0.52333\tvalid-mlogloss:0.71020                                                                    \n",
      "[600]\ttrain-mlogloss:0.48704\tvalid-mlogloss:0.69690                                                                    \n",
      "[700]\ttrain-mlogloss:0.45755\tvalid-mlogloss:0.68859                                                                    \n",
      "[800]\ttrain-mlogloss:0.43334\tvalid-mlogloss:0.68340                                                                    \n",
      "[900]\ttrain-mlogloss:0.41243\tvalid-mlogloss:0.68012                                                                    \n",
      "[1000]\ttrain-mlogloss:0.39561\tvalid-mlogloss:0.67828                                                                   \n",
      "[1100]\ttrain-mlogloss:0.38015\tvalid-mlogloss:0.67715                                                                   \n",
      "[1200]\ttrain-mlogloss:0.36676\tvalid-mlogloss:0.67672                                                                   \n",
      "[1245]\ttrain-mlogloss:0.36143\tvalid-mlogloss:0.67681                                                                   \n",
      "fold3 multi_logloss: 0.6768029704429889                                                                                \n",
      "[0]\ttrain-mlogloss:1.09579\tvalid-mlogloss:1.09644                                                                      \n",
      "[100]\ttrain-mlogloss:0.86633\tvalid-mlogloss:0.92189                                                                    \n",
      "[200]\ttrain-mlogloss:0.72781\tvalid-mlogloss:0.82814                                                                    \n",
      "[300]\ttrain-mlogloss:0.63545\tvalid-mlogloss:0.77390                                                                    \n",
      "[400]\ttrain-mlogloss:0.56935\tvalid-mlogloss:0.74163                                                                    \n",
      "[500]\ttrain-mlogloss:0.52059\tvalid-mlogloss:0.72219                                                                    \n",
      "[600]\ttrain-mlogloss:0.48400\tvalid-mlogloss:0.71115                                                                    \n",
      "[700]\ttrain-mlogloss:0.45450\tvalid-mlogloss:0.70472                                                                    \n",
      "[800]\ttrain-mlogloss:0.43019\tvalid-mlogloss:0.70105                                                                    \n",
      "[900]\ttrain-mlogloss:0.40939\tvalid-mlogloss:0.69918                                                                    \n",
      "[1000]\ttrain-mlogloss:0.39243\tvalid-mlogloss:0.69844                                                                   \n",
      "[1100]\ttrain-mlogloss:0.37706\tvalid-mlogloss:0.69823                                                                   \n",
      "[1101]\ttrain-mlogloss:0.37697\tvalid-mlogloss:0.69825                                                                   \n",
      "fold4 multi_logloss: 0.6982488735938281                                                                                \n",
      "[0]\ttrain-mlogloss:1.09574\tvalid-mlogloss:1.09646                                                                      \n",
      "[100]\ttrain-mlogloss:0.86606\tvalid-mlogloss:0.92341                                                                    \n",
      "[200]\ttrain-mlogloss:0.72725\tvalid-mlogloss:0.82965                                                                    \n",
      "[300]\ttrain-mlogloss:0.63494\tvalid-mlogloss:0.77545                                                                    \n",
      "[400]\ttrain-mlogloss:0.56881\tvalid-mlogloss:0.74241                                                                    \n",
      "[500]\ttrain-mlogloss:0.52003\tvalid-mlogloss:0.72219                                                                    \n",
      "[600]\ttrain-mlogloss:0.48343\tvalid-mlogloss:0.71048                                                                    \n",
      "[700]\ttrain-mlogloss:0.45403\tvalid-mlogloss:0.70332                                                                    \n",
      "[800]\ttrain-mlogloss:0.42980\tvalid-mlogloss:0.69882                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[900]\ttrain-mlogloss:0.40902\tvalid-mlogloss:0.69600                                                                    \n",
      "[1000]\ttrain-mlogloss:0.39214\tvalid-mlogloss:0.69469                                                                   \n",
      "[1100]\ttrain-mlogloss:0.37677\tvalid-mlogloss:0.69428                                                                   \n",
      "[1119]\ttrain-mlogloss:0.37404\tvalid-mlogloss:0.69423                                                                   \n",
      "fold5 multi_logloss: 0.6942333068415383                                                                                \n",
      "multi_logloss:                                                                                                         \n",
      "0.6913250815472309                                                                                                     \n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bylevel': 0.55, 'colsample_bytree': 0.55, 'eta': 0.004, 'eval_metric': 'mlogloss', 'gamma': 0.6000000000000001, 'max_depth': 100, 'min_child_weight': 2.0, 'num_class': 3, 'objective': 'multi:softprob', 'seed': 0, 'subsample': 0.7000000000000001}\n",
      "[0]\ttrain-mlogloss:1.09586\tvalid-mlogloss:1.09665                                                                      \n",
      "[100]\ttrain-mlogloss:0.87662\tvalid-mlogloss:0.94149                                                                    \n",
      "[200]\ttrain-mlogloss:0.73170\tvalid-mlogloss:0.84785                                                                    \n",
      "[300]\ttrain-mlogloss:0.63084\tvalid-mlogloss:0.79050                                                                    \n",
      "[400]\ttrain-mlogloss:0.55737\tvalid-mlogloss:0.75455                                                                    \n",
      "[500]\ttrain-mlogloss:0.50228\tvalid-mlogloss:0.73234                                                                    \n",
      "[600]\ttrain-mlogloss:0.45874\tvalid-mlogloss:0.71854                                                                    \n",
      "[700]\ttrain-mlogloss:0.42466\tvalid-mlogloss:0.71040                                                                    \n",
      "[800]\ttrain-mlogloss:0.39640\tvalid-mlogloss:0.70610                                                                    \n",
      "[900]\ttrain-mlogloss:0.37286\tvalid-mlogloss:0.70437                                                                    \n",
      "[1000]\ttrain-mlogloss:0.35343\tvalid-mlogloss:0.70416                                                                   \n",
      "[1001]\ttrain-mlogloss:0.35320\tvalid-mlogloss:0.70417                                                                   \n",
      "fold1 multi_logloss: 0.7041529764573389                                                                                \n",
      "[0]\ttrain-mlogloss:1.09591\tvalid-mlogloss:1.09655                                                                      \n",
      "[100]\ttrain-mlogloss:0.87875\tvalid-mlogloss:0.93732                                                                    \n",
      "[200]\ttrain-mlogloss:0.73438\tvalid-mlogloss:0.84052                                                                    \n",
      "[300]\ttrain-mlogloss:0.63343\tvalid-mlogloss:0.78035                                                                    \n",
      "[400]\ttrain-mlogloss:0.55978\tvalid-mlogloss:0.74241                                                                    \n",
      "[500]\ttrain-mlogloss:0.50441\tvalid-mlogloss:0.71861                                                                    \n",
      "[600]\ttrain-mlogloss:0.46054\tvalid-mlogloss:0.70383                                                                    \n",
      "[700]\ttrain-mlogloss:0.42628\tvalid-mlogloss:0.69481                                                                    \n",
      "[800]\ttrain-mlogloss:0.39781\tvalid-mlogloss:0.68991                                                                    \n",
      "[900]\ttrain-mlogloss:0.37398\tvalid-mlogloss:0.68771                                                                    \n",
      "[1000]\ttrain-mlogloss:0.35453\tvalid-mlogloss:0.68732                                                                   \n",
      "[1026]\ttrain-mlogloss:0.34986\tvalid-mlogloss:0.68741                                                                   \n",
      "fold2 multi_logloss: 0.6874113250265312                                                                                \n",
      "[0]\ttrain-mlogloss:1.09593\tvalid-mlogloss:1.09661                                                                      \n",
      "[100]\ttrain-mlogloss:0.87743\tvalid-mlogloss:0.93660                                                                    \n",
      "[200]\ttrain-mlogloss:0.73384\tvalid-mlogloss:0.84024                                                                    \n",
      "[300]\ttrain-mlogloss:0.63317\tvalid-mlogloss:0.77944                                                                    \n",
      "[400]\ttrain-mlogloss:0.55934\tvalid-mlogloss:0.74035                                                                    \n",
      "[500]\ttrain-mlogloss:0.50393\tvalid-mlogloss:0.71534                                                                    \n",
      "[600]\ttrain-mlogloss:0.46203\tvalid-mlogloss:0.69973                                                                    \n",
      "[700]\ttrain-mlogloss:0.42814\tvalid-mlogloss:0.69001                                                                    \n",
      "[800]\ttrain-mlogloss:0.40075\tvalid-mlogloss:0.68421                                                                    \n",
      "[900]\ttrain-mlogloss:0.37777\tvalid-mlogloss:0.68097                                                                    \n",
      "[1000]\ttrain-mlogloss:0.35864\tvalid-mlogloss:0.67956                                                                   \n",
      "[1100]\ttrain-mlogloss:0.34166\tvalid-mlogloss:0.67931                                                                   \n",
      "[1102]\ttrain-mlogloss:0.34136\tvalid-mlogloss:0.67931                                                                   \n",
      "fold3 multi_logloss: 0.679308779323705                                                                                 \n",
      "[0]\ttrain-mlogloss:1.09587\tvalid-mlogloss:1.09658                                                                      \n",
      "[100]\ttrain-mlogloss:0.87619\tvalid-mlogloss:0.93933                                                                    \n",
      "[200]\ttrain-mlogloss:0.73189\tvalid-mlogloss:0.84570                                                                    \n",
      "[300]\ttrain-mlogloss:0.63063\tvalid-mlogloss:0.78705                                                                    \n",
      "[400]\ttrain-mlogloss:0.55659\tvalid-mlogloss:0.75029                                                                    \n",
      "[500]\ttrain-mlogloss:0.50116\tvalid-mlogloss:0.72762                                                                    \n",
      "[600]\ttrain-mlogloss:0.45916\tvalid-mlogloss:0.71416                                                                    \n",
      "[700]\ttrain-mlogloss:0.42526\tvalid-mlogloss:0.70629                                                                    \n",
      "[800]\ttrain-mlogloss:0.39782\tvalid-mlogloss:0.70221                                                                    \n",
      "[900]\ttrain-mlogloss:0.37481\tvalid-mlogloss:0.70040                                                                    \n",
      "[1000]\ttrain-mlogloss:0.35588\tvalid-mlogloss:0.70002                                                                   \n",
      "[1010]\ttrain-mlogloss:0.35412\tvalid-mlogloss:0.70003                                                                   \n",
      "fold4 multi_logloss: 0.7000330565359346                                                                                \n",
      "[0]\ttrain-mlogloss:1.09588\tvalid-mlogloss:1.09659                                                                      \n",
      "[100]\ttrain-mlogloss:0.87620\tvalid-mlogloss:0.94053                                                                    \n",
      "[200]\ttrain-mlogloss:0.73179\tvalid-mlogloss:0.84706                                                                    \n",
      "[300]\ttrain-mlogloss:0.63040\tvalid-mlogloss:0.78835                                                                    \n",
      "[400]\ttrain-mlogloss:0.55614\tvalid-mlogloss:0.75097                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500]\ttrain-mlogloss:0.50043\tvalid-mlogloss:0.72714                                                                    \n",
      "[600]\ttrain-mlogloss:0.45825\tvalid-mlogloss:0.71294                                                                    \n",
      "[700]\ttrain-mlogloss:0.42433\tvalid-mlogloss:0.70449                                                                    \n",
      "[800]\ttrain-mlogloss:0.39695\tvalid-mlogloss:0.69969                                                                    \n",
      "[900]\ttrain-mlogloss:0.37393\tvalid-mlogloss:0.69732                                                                    \n",
      "[1000]\ttrain-mlogloss:0.35488\tvalid-mlogloss:0.69653                                                                   \n",
      "[1011]\ttrain-mlogloss:0.35290\tvalid-mlogloss:0.69656                                                                   \n",
      "fold5 multi_logloss: 0.6965453884133188                                                                                \n",
      "multi_logloss:                                                                                                         \n",
      "0.6934904784019679                                                                                                     \n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bylevel': 0.55, 'colsample_bytree': 0.4, 'eta': 0.004, 'eval_metric': 'mlogloss', 'gamma': 0.75, 'max_depth': 100, 'min_child_weight': 2.0, 'num_class': 3, 'objective': 'multi:softprob', 'seed': 0, 'subsample': 0.65}\n",
      "[0]\ttrain-mlogloss:1.09595\tvalid-mlogloss:1.09664                                                                      \n",
      "[100]\ttrain-mlogloss:0.89098\tvalid-mlogloss:0.94837                                                                    \n",
      "[200]\ttrain-mlogloss:0.75569\tvalid-mlogloss:0.85826                                                                    \n",
      "[300]\ttrain-mlogloss:0.66164\tvalid-mlogloss:0.80184                                                                    \n",
      "[400]\ttrain-mlogloss:0.59271\tvalid-mlogloss:0.76553                                                                    \n",
      "[500]\ttrain-mlogloss:0.54197\tvalid-mlogloss:0.74280                                                                    \n",
      "[600]\ttrain-mlogloss:0.50133\tvalid-mlogloss:0.72788                                                                    \n",
      "[700]\ttrain-mlogloss:0.46951\tvalid-mlogloss:0.71842                                                                    \n",
      "[800]\ttrain-mlogloss:0.44203\tvalid-mlogloss:0.71211                                                                    \n",
      "[900]\ttrain-mlogloss:0.41995\tvalid-mlogloss:0.70846                                                                    \n",
      "[1000]\ttrain-mlogloss:0.40167\tvalid-mlogloss:0.70634                                                                   \n",
      "[1100]\ttrain-mlogloss:0.38510\tvalid-mlogloss:0.70522                                                                   \n",
      "[1200]\ttrain-mlogloss:0.37058\tvalid-mlogloss:0.70467                                                                   \n",
      "[1226]\ttrain-mlogloss:0.36748\tvalid-mlogloss:0.70471                                                                   \n",
      "fold1 multi_logloss: 0.7047128231961974                                                                                \n",
      "[0]\ttrain-mlogloss:1.09604\tvalid-mlogloss:1.09668                                                                      \n",
      "[100]\ttrain-mlogloss:0.89349\tvalid-mlogloss:0.94359                                                                    \n",
      "[200]\ttrain-mlogloss:0.75901\tvalid-mlogloss:0.85000                                                                    \n",
      "[300]\ttrain-mlogloss:0.66507\tvalid-mlogloss:0.79093                                                                    \n",
      "[400]\ttrain-mlogloss:0.59608\tvalid-mlogloss:0.75272                                                                    \n",
      "[500]\ttrain-mlogloss:0.54517\tvalid-mlogloss:0.72825                                                                    \n",
      "[600]\ttrain-mlogloss:0.50431\tvalid-mlogloss:0.71222                                                                    \n",
      "[700]\ttrain-mlogloss:0.47234\tvalid-mlogloss:0.70178                                                                    \n",
      "[800]\ttrain-mlogloss:0.44476\tvalid-mlogloss:0.69475                                                                    \n",
      "[900]\ttrain-mlogloss:0.42255\tvalid-mlogloss:0.69052                                                                    \n",
      "[1000]\ttrain-mlogloss:0.40429\tvalid-mlogloss:0.68801                                                                   \n",
      "[1100]\ttrain-mlogloss:0.38771\tvalid-mlogloss:0.68661                                                                   \n",
      "[1200]\ttrain-mlogloss:0.37308\tvalid-mlogloss:0.68607                                                                   \n",
      "[1215]\ttrain-mlogloss:0.37138\tvalid-mlogloss:0.68612                                                                   \n",
      "fold2 multi_logloss: 0.6861202159716278                                                                                \n",
      "[0]\ttrain-mlogloss:1.09622\tvalid-mlogloss:1.09680                                                                      \n",
      "[100]\ttrain-mlogloss:0.89234\tvalid-mlogloss:0.94345                                                                    \n",
      "[200]\ttrain-mlogloss:0.75935\tvalid-mlogloss:0.85077                                                                    \n",
      "[300]\ttrain-mlogloss:0.66592\tvalid-mlogloss:0.79176                                                                    \n",
      "[400]\ttrain-mlogloss:0.59646\tvalid-mlogloss:0.75244                                                                    \n",
      "[500]\ttrain-mlogloss:0.54396\tvalid-mlogloss:0.72649                                                                    \n",
      "[600]\ttrain-mlogloss:0.50452\tvalid-mlogloss:0.70995                                                                    \n",
      "[700]\ttrain-mlogloss:0.47298\tvalid-mlogloss:0.69879                                                                    \n",
      "[800]\ttrain-mlogloss:0.44750\tvalid-mlogloss:0.69132                                                                    \n",
      "[900]\ttrain-mlogloss:0.42535\tvalid-mlogloss:0.68620                                                                    \n",
      "[1000]\ttrain-mlogloss:0.40747\tvalid-mlogloss:0.68300                                                                   \n",
      "[1100]\ttrain-mlogloss:0.39096\tvalid-mlogloss:0.68062                                                                   \n",
      "[1200]\ttrain-mlogloss:0.37675\tvalid-mlogloss:0.67947                                                                   \n",
      "[1300]\ttrain-mlogloss:0.36408\tvalid-mlogloss:0.67869                                                                   \n",
      "[1374]\ttrain-mlogloss:0.35457\tvalid-mlogloss:0.67847                                                                   \n",
      "fold3 multi_logloss: 0.6784716689549178                                                                                \n",
      "[0]\ttrain-mlogloss:1.09621\tvalid-mlogloss:1.09683                                                                      \n",
      "[100]\ttrain-mlogloss:0.89133\tvalid-mlogloss:0.94543                                                                    \n",
      "[200]\ttrain-mlogloss:0.75751\tvalid-mlogloss:0.85501                                                                    \n",
      "[300]\ttrain-mlogloss:0.66351\tvalid-mlogloss:0.79795                                                                    \n",
      "[400]\ttrain-mlogloss:0.59388\tvalid-mlogloss:0.76080                                                                    \n",
      "[500]\ttrain-mlogloss:0.54131\tvalid-mlogloss:0.73636                                                                    \n",
      "[600]\ttrain-mlogloss:0.50166\tvalid-mlogloss:0.72154                                                                    \n",
      "[700]\ttrain-mlogloss:0.47005\tvalid-mlogloss:0.71235                                                                    \n",
      "[800]\ttrain-mlogloss:0.44451\tvalid-mlogloss:0.70651                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[900]\ttrain-mlogloss:0.42241\tvalid-mlogloss:0.70271                                                                    \n",
      "[1000]\ttrain-mlogloss:0.40446\tvalid-mlogloss:0.70068                                                                   \n",
      "[1100]\ttrain-mlogloss:0.38794\tvalid-mlogloss:0.69945                                                                   \n",
      "[1188]\ttrain-mlogloss:0.37549\tvalid-mlogloss:0.69905                                                                   \n",
      "fold4 multi_logloss: 0.6990671144048073                                                                                \n",
      "[0]\ttrain-mlogloss:1.09621\tvalid-mlogloss:1.09688                                                                      \n",
      "[100]\ttrain-mlogloss:0.89090\tvalid-mlogloss:0.94720                                                                    \n",
      "[200]\ttrain-mlogloss:0.75704\tvalid-mlogloss:0.85733                                                                    \n",
      "[300]\ttrain-mlogloss:0.66301\tvalid-mlogloss:0.80033                                                                    \n",
      "[400]\ttrain-mlogloss:0.59318\tvalid-mlogloss:0.76291                                                                    \n",
      "[500]\ttrain-mlogloss:0.54063\tvalid-mlogloss:0.73852                                                                    \n",
      "[600]\ttrain-mlogloss:0.50099\tvalid-mlogloss:0.72338                                                                    \n",
      "[700]\ttrain-mlogloss:0.46931\tvalid-mlogloss:0.71343                                                                    \n",
      "[800]\ttrain-mlogloss:0.44368\tvalid-mlogloss:0.70701                                                                    \n",
      "[900]\ttrain-mlogloss:0.42151\tvalid-mlogloss:0.70246                                                                    \n",
      "[1000]\ttrain-mlogloss:0.40365\tvalid-mlogloss:0.69997                                                                   \n",
      "[1100]\ttrain-mlogloss:0.38724\tvalid-mlogloss:0.69821                                                                   \n",
      "[1200]\ttrain-mlogloss:0.37312\tvalid-mlogloss:0.69741                                                                   \n",
      "[1238]\ttrain-mlogloss:0.36824\tvalid-mlogloss:0.69743                                                                   \n",
      "fold5 multi_logloss: 0.6974291585808992                                                                                \n",
      "multi_logloss:                                                                                                         \n",
      "0.693160366787012                                                                                                      \n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bylevel': 0.55, 'colsample_bytree': 0.35000000000000003, 'eta': 0.004, 'eval_metric': 'mlogloss', 'gamma': 0.65, 'max_depth': 100, 'min_child_weight': 2.0, 'num_class': 3, 'objective': 'multi:softprob', 'seed': 0, 'subsample': 0.7000000000000001}\n",
      "[0]\ttrain-mlogloss:1.09597\tvalid-mlogloss:1.09667                                                                      \n",
      "[100]\ttrain-mlogloss:0.89049\tvalid-mlogloss:0.94829                                                                    \n",
      "[200]\ttrain-mlogloss:0.75502\tvalid-mlogloss:0.85898                                                                    \n",
      "[300]\ttrain-mlogloss:0.66049\tvalid-mlogloss:0.80304                                                                    \n",
      "[400]\ttrain-mlogloss:0.59058\tvalid-mlogloss:0.76676                                                                    \n",
      "[500]\ttrain-mlogloss:0.53962\tvalid-mlogloss:0.74428                                                                    \n",
      "[600]\ttrain-mlogloss:0.49859\tvalid-mlogloss:0.72971                                                                    \n",
      "[700]\ttrain-mlogloss:0.46686\tvalid-mlogloss:0.72063                                                                    \n",
      "[800]\ttrain-mlogloss:0.43868\tvalid-mlogloss:0.71411                                                                    \n",
      "[900]\ttrain-mlogloss:0.41626\tvalid-mlogloss:0.71047                                                                    \n",
      "[1000]\ttrain-mlogloss:0.39767\tvalid-mlogloss:0.70843                                                                   \n",
      "[1100]\ttrain-mlogloss:0.38118\tvalid-mlogloss:0.70727                                                                   \n",
      "[1200]\ttrain-mlogloss:0.36610\tvalid-mlogloss:0.70679                                                                   \n",
      "[1219]\ttrain-mlogloss:0.36374\tvalid-mlogloss:0.70681                                                                   \n",
      "fold1 multi_logloss: 0.7068151186525486                                                                                \n",
      "[0]\ttrain-mlogloss:1.09599\tvalid-mlogloss:1.09661                                                                      \n",
      "[100]\ttrain-mlogloss:0.89264\tvalid-mlogloss:0.94374                                                                    \n",
      "[200]\ttrain-mlogloss:0.75798\tvalid-mlogloss:0.85066                                                                    \n",
      "[300]\ttrain-mlogloss:0.66352\tvalid-mlogloss:0.79181                                                                    \n",
      "[400]\ttrain-mlogloss:0.59362\tvalid-mlogloss:0.75333                                                                    \n",
      "[500]\ttrain-mlogloss:0.54252\tvalid-mlogloss:0.72910                                                                    \n",
      "[600]\ttrain-mlogloss:0.50139\tvalid-mlogloss:0.71315                                                                    \n",
      "[700]\ttrain-mlogloss:0.46950\tvalid-mlogloss:0.70291                                                                    \n",
      "[800]\ttrain-mlogloss:0.44112\tvalid-mlogloss:0.69569                                                                    \n",
      "[900]\ttrain-mlogloss:0.41867\tvalid-mlogloss:0.69131                                                                    \n",
      "[1000]\ttrain-mlogloss:0.39999\tvalid-mlogloss:0.68881                                                                   \n",
      "[1100]\ttrain-mlogloss:0.38350\tvalid-mlogloss:0.68749                                                                   \n",
      "[1200]\ttrain-mlogloss:0.36832\tvalid-mlogloss:0.68707                                                                   \n",
      "[1300]\ttrain-mlogloss:0.35519\tvalid-mlogloss:0.68702                                                                   \n",
      "[1312]\ttrain-mlogloss:0.35361\tvalid-mlogloss:0.68707                                                                   \n",
      "fold2 multi_logloss: 0.687065689394911                                                                                 \n",
      "[0]\ttrain-mlogloss:1.09624\tvalid-mlogloss:1.09681                                                                      \n",
      "[100]\ttrain-mlogloss:0.89206\tvalid-mlogloss:0.94432                                                                    \n",
      "[200]\ttrain-mlogloss:0.75977\tvalid-mlogloss:0.85258                                                                    \n",
      "[300]\ttrain-mlogloss:0.66596\tvalid-mlogloss:0.79354                                                                    \n",
      "[400]\ttrain-mlogloss:0.59663\tvalid-mlogloss:0.75506                                                                    \n",
      "[500]\ttrain-mlogloss:0.54368\tvalid-mlogloss:0.72890                                                                    \n",
      "[600]\ttrain-mlogloss:0.50395\tvalid-mlogloss:0.71235                                                                    \n",
      "[700]\ttrain-mlogloss:0.47173\tvalid-mlogloss:0.70113                                                                    \n",
      "[800]\ttrain-mlogloss:0.44604\tvalid-mlogloss:0.69371                                                                    \n",
      "[900]\ttrain-mlogloss:0.42352\tvalid-mlogloss:0.68856                                                                    \n",
      "[1000]\ttrain-mlogloss:0.40522\tvalid-mlogloss:0.68545                                                                   \n",
      "[1100]\ttrain-mlogloss:0.38857\tvalid-mlogloss:0.68317                                                                   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1200]\ttrain-mlogloss:0.37406\tvalid-mlogloss:0.68180                                                                   \n",
      "[1300]\ttrain-mlogloss:0.36130\tvalid-mlogloss:0.68102                                                                   \n",
      "[1400]\ttrain-mlogloss:0.34872\tvalid-mlogloss:0.68054                                                                   \n",
      "[1450]\ttrain-mlogloss:0.34371\tvalid-mlogloss:0.68050                                                                   \n",
      "fold3 multi_logloss: 0.680501810803211                                                                                 \n",
      "[0]\ttrain-mlogloss:1.09623\tvalid-mlogloss:1.09688                                                                      \n",
      "[100]\ttrain-mlogloss:0.89095\tvalid-mlogloss:0.94642                                                                    \n",
      "[200]\ttrain-mlogloss:0.75789\tvalid-mlogloss:0.85716                                                                    \n",
      "[300]\ttrain-mlogloss:0.66355\tvalid-mlogloss:0.80029                                                                    \n",
      "[400]\ttrain-mlogloss:0.59391\tvalid-mlogloss:0.76392                                                                    \n",
      "[500]\ttrain-mlogloss:0.54081\tvalid-mlogloss:0.73974                                                                    \n",
      "[600]\ttrain-mlogloss:0.50102\tvalid-mlogloss:0.72515                                                                    \n",
      "[700]\ttrain-mlogloss:0.46887\tvalid-mlogloss:0.71575                                                                    \n",
      "[800]\ttrain-mlogloss:0.44308\tvalid-mlogloss:0.70994                                                                    \n",
      "[900]\ttrain-mlogloss:0.42051\tvalid-mlogloss:0.70576                                                                    \n",
      "[1000]\ttrain-mlogloss:0.40242\tvalid-mlogloss:0.70350                                                                   \n",
      "[1100]\ttrain-mlogloss:0.38583\tvalid-mlogloss:0.70210                                                                   \n",
      "[1200]\ttrain-mlogloss:0.37122\tvalid-mlogloss:0.70171                                                                   \n",
      "[1264]\ttrain-mlogloss:0.36296\tvalid-mlogloss:0.70173                                                                   \n",
      "fold4 multi_logloss: 0.7017573489355236                                                                                \n",
      "[0]\ttrain-mlogloss:1.09621\tvalid-mlogloss:1.09687                                                                      \n",
      "[100]\ttrain-mlogloss:0.89057\tvalid-mlogloss:0.94845                                                                    \n",
      "[200]\ttrain-mlogloss:0.75719\tvalid-mlogloss:0.85996                                                                    \n",
      "[300]\ttrain-mlogloss:0.66281\tvalid-mlogloss:0.80343                                                                    \n",
      "[400]\ttrain-mlogloss:0.59309\tvalid-mlogloss:0.76671                                                                    \n",
      "[500]\ttrain-mlogloss:0.53991\tvalid-mlogloss:0.74234                                                                    \n",
      "[600]\ttrain-mlogloss:0.49999\tvalid-mlogloss:0.72707                                                                    \n",
      "[700]\ttrain-mlogloss:0.46755\tvalid-mlogloss:0.71710                                                                    \n",
      "[800]\ttrain-mlogloss:0.44174\tvalid-mlogloss:0.71060                                                                    \n",
      "[900]\ttrain-mlogloss:0.41920\tvalid-mlogloss:0.70599                                                                    \n",
      "[1000]\ttrain-mlogloss:0.40095\tvalid-mlogloss:0.70308                                                                   \n",
      "[1100]\ttrain-mlogloss:0.38438\tvalid-mlogloss:0.70127                                                                   \n",
      "[1200]\ttrain-mlogloss:0.37002\tvalid-mlogloss:0.70041                                                                   \n",
      "[1300]\ttrain-mlogloss:0.35731\tvalid-mlogloss:0.70008                                                                   \n",
      "[1400]\ttrain-mlogloss:0.34480\tvalid-mlogloss:0.69969                                                                   \n",
      "[1412]\ttrain-mlogloss:0.34361\tvalid-mlogloss:0.69974                                                                   \n",
      "fold5 multi_logloss: 0.6997383178319583                                                                                \n",
      "multi_logloss:                                                                                                         \n",
      "0.6951757905285442                                                                                                     \n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bylevel': 0.5, 'colsample_bytree': 0.65, 'eta': 0.005, 'eval_metric': 'mlogloss', 'gamma': 0.8, 'max_depth': 100, 'min_child_weight': 2.0, 'num_class': 3, 'objective': 'multi:softprob', 'seed': 0, 'subsample': 0.7000000000000001}\n",
      "[0]\ttrain-mlogloss:1.09518\tvalid-mlogloss:1.09607                                                                      \n",
      "[100]\ttrain-mlogloss:0.83372\tvalid-mlogloss:0.91209                                                                    \n",
      "[200]\ttrain-mlogloss:0.67630\tvalid-mlogloss:0.81348                                                                    \n",
      "[300]\ttrain-mlogloss:0.57518\tvalid-mlogloss:0.76007                                                                    \n",
      "[400]\ttrain-mlogloss:0.50515\tvalid-mlogloss:0.73057                                                                    \n",
      "[500]\ttrain-mlogloss:0.45498\tvalid-mlogloss:0.71524                                                                    \n",
      "[600]\ttrain-mlogloss:0.41642\tvalid-mlogloss:0.70753                                                                    \n",
      "[700]\ttrain-mlogloss:0.38672\tvalid-mlogloss:0.70401                                                                    \n",
      "[800]\ttrain-mlogloss:0.36274\tvalid-mlogloss:0.70316                                                                    \n",
      "[801]\ttrain-mlogloss:0.36249\tvalid-mlogloss:0.70315                                                                    \n",
      "fold1 multi_logloss: 0.7031539576162895                                                                                \n",
      "[0]\ttrain-mlogloss:1.09524\tvalid-mlogloss:1.09610                                                                      \n",
      "[100]\ttrain-mlogloss:0.83606\tvalid-mlogloss:0.90717                                                                    \n",
      "[200]\ttrain-mlogloss:0.67900\tvalid-mlogloss:0.80507                                                                    \n",
      "[300]\ttrain-mlogloss:0.57761\tvalid-mlogloss:0.74920                                                                    \n",
      "[400]\ttrain-mlogloss:0.50745\tvalid-mlogloss:0.71792                                                                    \n",
      "[500]\ttrain-mlogloss:0.45690\tvalid-mlogloss:0.70120                                                                    \n",
      "[600]\ttrain-mlogloss:0.41820\tvalid-mlogloss:0.69255                                                                    \n",
      "[700]\ttrain-mlogloss:0.38835\tvalid-mlogloss:0.68880                                                                    \n",
      "[800]\ttrain-mlogloss:0.36424\tvalid-mlogloss:0.68806                                                                    \n",
      "[846]\ttrain-mlogloss:0.35483\tvalid-mlogloss:0.68817                                                                    \n",
      "fold2 multi_logloss: 0.6881936104703698                                                                                \n",
      "[0]\ttrain-mlogloss:1.09525\tvalid-mlogloss:1.09611                                                                      \n",
      "[100]\ttrain-mlogloss:0.83481\tvalid-mlogloss:0.90510                                                                    \n",
      "[200]\ttrain-mlogloss:0.67968\tvalid-mlogloss:0.80351                                                                    \n",
      "[300]\ttrain-mlogloss:0.57773\tvalid-mlogloss:0.74659                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[400]\ttrain-mlogloss:0.50835\tvalid-mlogloss:0.71480                                                                    \n",
      "[500]\ttrain-mlogloss:0.45796\tvalid-mlogloss:0.69675                                                                    \n",
      "[600]\ttrain-mlogloss:0.42054\tvalid-mlogloss:0.68724                                                                    \n",
      "[700]\ttrain-mlogloss:0.39109\tvalid-mlogloss:0.68239                                                                    \n",
      "[800]\ttrain-mlogloss:0.36706\tvalid-mlogloss:0.68023                                                                    \n",
      "[889]\ttrain-mlogloss:0.34924\tvalid-mlogloss:0.68014                                                                    \n",
      "fold3 multi_logloss: 0.680140844469776                                                                                 \n",
      "[0]\ttrain-mlogloss:1.09523\tvalid-mlogloss:1.09611                                                                      \n",
      "[100]\ttrain-mlogloss:0.83312\tvalid-mlogloss:0.90877                                                                    \n",
      "[200]\ttrain-mlogloss:0.67697\tvalid-mlogloss:0.81049                                                                    \n",
      "[300]\ttrain-mlogloss:0.57461\tvalid-mlogloss:0.75608                                                                    \n",
      "[400]\ttrain-mlogloss:0.50527\tvalid-mlogloss:0.72679                                                                    \n",
      "[500]\ttrain-mlogloss:0.45501\tvalid-mlogloss:0.71089                                                                    \n",
      "[600]\ttrain-mlogloss:0.41784\tvalid-mlogloss:0.70324                                                                    \n",
      "[700]\ttrain-mlogloss:0.38867\tvalid-mlogloss:0.70017                                                                    \n",
      "[781]\ttrain-mlogloss:0.36925\tvalid-mlogloss:0.69959                                                                    \n",
      "fold4 multi_logloss: 0.6995858207020793                                                                                \n",
      "[0]\ttrain-mlogloss:1.09521\tvalid-mlogloss:1.09611                                                                      \n",
      "[100]\ttrain-mlogloss:0.83287\tvalid-mlogloss:0.90980                                                                    \n",
      "[200]\ttrain-mlogloss:0.67686\tvalid-mlogloss:0.81179                                                                    \n",
      "[300]\ttrain-mlogloss:0.57423\tvalid-mlogloss:0.75679                                                                    \n",
      "[400]\ttrain-mlogloss:0.50464\tvalid-mlogloss:0.72670                                                                    \n",
      "[500]\ttrain-mlogloss:0.45434\tvalid-mlogloss:0.70991                                                                    \n",
      "[600]\ttrain-mlogloss:0.41690\tvalid-mlogloss:0.70148                                                                    \n",
      "[700]\ttrain-mlogloss:0.38755\tvalid-mlogloss:0.69754                                                                    \n",
      "[800]\ttrain-mlogloss:0.36363\tvalid-mlogloss:0.69609                                                                    \n",
      "[874]\ttrain-mlogloss:0.34857\tvalid-mlogloss:0.69608                                                                    \n",
      "fold5 multi_logloss: 0.6960828989692183                                                                                \n",
      "multi_logloss:                                                                                                         \n",
      "0.6934315959551355                                                                                                     \n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bylevel': 0.5, 'colsample_bytree': 0.45, 'eta': 0.006, 'eval_metric': 'mlogloss', 'gamma': 0.7000000000000001, 'max_depth': 100, 'min_child_weight': 2.0, 'num_class': 3, 'objective': 'multi:softprob', 'seed': 0, 'subsample': 0.75}\n",
      "[0]\ttrain-mlogloss:1.09448\tvalid-mlogloss:1.09558                                                                      \n",
      "[100]\ttrain-mlogloss:0.80329\tvalid-mlogloss:0.89155                                                                    \n",
      "[200]\ttrain-mlogloss:0.64160\tvalid-mlogloss:0.79418                                                                    \n",
      "[300]\ttrain-mlogloss:0.54260\tvalid-mlogloss:0.74630                                                                    \n",
      "[400]\ttrain-mlogloss:0.47641\tvalid-mlogloss:0.72230                                                                    \n",
      "[500]\ttrain-mlogloss:0.43024\tvalid-mlogloss:0.71074                                                                    \n",
      "[600]\ttrain-mlogloss:0.39415\tvalid-mlogloss:0.70551                                                                    \n",
      "[700]\ttrain-mlogloss:0.36716\tvalid-mlogloss:0.70389                                                                    \n",
      "[752]\ttrain-mlogloss:0.35504\tvalid-mlogloss:0.70407                                                                    \n",
      "fold1 multi_logloss: 0.7040690387671455                                                                                \n",
      "[0]\ttrain-mlogloss:1.09459\tvalid-mlogloss:1.09559                                                                      \n",
      "[100]\ttrain-mlogloss:0.80624\tvalid-mlogloss:0.88554                                                                    \n",
      "[200]\ttrain-mlogloss:0.64449\tvalid-mlogloss:0.78387                                                                    \n",
      "[300]\ttrain-mlogloss:0.54501\tvalid-mlogloss:0.73267                                                                    \n",
      "[400]\ttrain-mlogloss:0.47872\tvalid-mlogloss:0.70661                                                                    \n",
      "[500]\ttrain-mlogloss:0.43219\tvalid-mlogloss:0.69425                                                                    \n",
      "[600]\ttrain-mlogloss:0.39587\tvalid-mlogloss:0.68894                                                                    \n",
      "[700]\ttrain-mlogloss:0.36881\tvalid-mlogloss:0.68678                                                                    \n",
      "[760]\ttrain-mlogloss:0.35490\tvalid-mlogloss:0.68660                                                                    \n",
      "fold2 multi_logloss: 0.6866042840660931                                                                                \n",
      "[0]\ttrain-mlogloss:1.09482\tvalid-mlogloss:1.09577                                                                      \n",
      "[100]\ttrain-mlogloss:0.80408\tvalid-mlogloss:0.88477                                                                    \n",
      "[200]\ttrain-mlogloss:0.64480\tvalid-mlogloss:0.78336                                                                    \n",
      "[300]\ttrain-mlogloss:0.54616\tvalid-mlogloss:0.73167                                                                    \n",
      "[400]\ttrain-mlogloss:0.47902\tvalid-mlogloss:0.70395                                                                    \n",
      "[500]\ttrain-mlogloss:0.43140\tvalid-mlogloss:0.68988                                                                    \n",
      "[600]\ttrain-mlogloss:0.39776\tvalid-mlogloss:0.68283                                                                    \n",
      "[700]\ttrain-mlogloss:0.37066\tvalid-mlogloss:0.67955                                                                    \n",
      "[800]\ttrain-mlogloss:0.34909\tvalid-mlogloss:0.67852                                                                    \n",
      "[845]\ttrain-mlogloss:0.34012\tvalid-mlogloss:0.67858                                                                    \n",
      "fold3 multi_logloss: 0.6785750015428682                                                                                \n",
      "[0]\ttrain-mlogloss:1.09478\tvalid-mlogloss:1.09586                                                                      \n",
      "[100]\ttrain-mlogloss:0.80234\tvalid-mlogloss:0.88828                                                                    \n",
      "[200]\ttrain-mlogloss:0.64228\tvalid-mlogloss:0.79072                                                                    \n",
      "[300]\ttrain-mlogloss:0.54330\tvalid-mlogloss:0.74253                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[400]\ttrain-mlogloss:0.47610\tvalid-mlogloss:0.71782                                                                    \n",
      "[500]\ttrain-mlogloss:0.42848\tvalid-mlogloss:0.70582                                                                    \n",
      "[600]\ttrain-mlogloss:0.39489\tvalid-mlogloss:0.70116                                                                    \n",
      "[700]\ttrain-mlogloss:0.36779\tvalid-mlogloss:0.69986                                                                    \n",
      "[749]\ttrain-mlogloss:0.35725\tvalid-mlogloss:0.69991                                                                    \n",
      "fold4 multi_logloss: 0.6999526742810823                                                                                \n",
      "[0]\ttrain-mlogloss:1.09477\tvalid-mlogloss:1.09592                                                                      \n",
      "[100]\ttrain-mlogloss:0.80226\tvalid-mlogloss:0.88977                                                                    \n",
      "[200]\ttrain-mlogloss:0.64202\tvalid-mlogloss:0.79224                                                                    \n",
      "[300]\ttrain-mlogloss:0.54310\tvalid-mlogloss:0.74304                                                                    \n",
      "[400]\ttrain-mlogloss:0.47585\tvalid-mlogloss:0.71761                                                                    \n",
      "[500]\ttrain-mlogloss:0.42803\tvalid-mlogloss:0.70449                                                                    \n",
      "[600]\ttrain-mlogloss:0.39424\tvalid-mlogloss:0.69890                                                                    \n",
      "[700]\ttrain-mlogloss:0.36725\tvalid-mlogloss:0.69647                                                                    \n",
      "[800]\ttrain-mlogloss:0.34582\tvalid-mlogloss:0.69620                                                                    \n",
      "[835]\ttrain-mlogloss:0.33896\tvalid-mlogloss:0.69626                                                                    \n",
      "fold5 multi_logloss: 0.6962510587487085                                                                                \n",
      "multi_logloss:                                                                                                         \n",
      "0.6930905812850073                                                                                                     \n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bylevel': 0.45, 'colsample_bytree': 0.5, 'eta': 0.005, 'eval_metric': 'mlogloss', 'gamma': 0.75, 'max_depth': 100, 'min_child_weight': 3.0, 'num_class': 3, 'objective': 'multi:softprob', 'seed': 0, 'subsample': 0.7000000000000001}\n",
      "[0]\ttrain-mlogloss:1.09546\tvalid-mlogloss:1.09628                                                                      \n",
      "[100]\ttrain-mlogloss:0.85625\tvalid-mlogloss:0.92078                                                                    \n",
      "[200]\ttrain-mlogloss:0.71083\tvalid-mlogloss:0.82562                                                                    \n",
      "[300]\ttrain-mlogloss:0.61547\tvalid-mlogloss:0.77198                                                                    \n",
      "[400]\ttrain-mlogloss:0.54887\tvalid-mlogloss:0.74077                                                                    \n",
      "[500]\ttrain-mlogloss:0.50023\tvalid-mlogloss:0.72297                                                                    \n",
      "[600]\ttrain-mlogloss:0.46236\tvalid-mlogloss:0.71300                                                                    \n",
      "[700]\ttrain-mlogloss:0.43320\tvalid-mlogloss:0.70756                                                                    \n",
      "[800]\ttrain-mlogloss:0.40856\tvalid-mlogloss:0.70467                                                                    \n",
      "[900]\ttrain-mlogloss:0.38838\tvalid-mlogloss:0.70342                                                                    \n",
      "[963]\ttrain-mlogloss:0.37715\tvalid-mlogloss:0.70330                                                                    \n",
      "fold1 multi_logloss: 0.7033038568517466                                                                                \n",
      "[0]\ttrain-mlogloss:1.09549\tvalid-mlogloss:1.09619                                                                      \n",
      "[100]\ttrain-mlogloss:0.85914\tvalid-mlogloss:0.91568                                                                    \n",
      "[200]\ttrain-mlogloss:0.71458\tvalid-mlogloss:0.81658                                                                    \n",
      "[300]\ttrain-mlogloss:0.61907\tvalid-mlogloss:0.76021                                                                    \n",
      "[400]\ttrain-mlogloss:0.55204\tvalid-mlogloss:0.72733                                                                    \n",
      "[500]\ttrain-mlogloss:0.50320\tvalid-mlogloss:0.70807                                                                    \n",
      "[600]\ttrain-mlogloss:0.46512\tvalid-mlogloss:0.69686                                                                    \n",
      "[700]\ttrain-mlogloss:0.43573\tvalid-mlogloss:0.69055                                                                    \n",
      "[800]\ttrain-mlogloss:0.41089\tvalid-mlogloss:0.68713                                                                    \n",
      "[900]\ttrain-mlogloss:0.39051\tvalid-mlogloss:0.68600                                                                    \n",
      "[991]\ttrain-mlogloss:0.37470\tvalid-mlogloss:0.68579                                                                    \n",
      "fold2 multi_logloss: 0.6857967834021368                                                                                \n",
      "[0]\ttrain-mlogloss:1.09570\tvalid-mlogloss:1.09639                                                                      \n",
      "[100]\ttrain-mlogloss:0.85731\tvalid-mlogloss:0.91556                                                                    \n",
      "[200]\ttrain-mlogloss:0.71374\tvalid-mlogloss:0.81719                                                                    \n",
      "[300]\ttrain-mlogloss:0.61892\tvalid-mlogloss:0.76006                                                                    \n",
      "[400]\ttrain-mlogloss:0.55193\tvalid-mlogloss:0.72604                                                                    \n",
      "[500]\ttrain-mlogloss:0.50288\tvalid-mlogloss:0.70574                                                                    \n",
      "[600]\ttrain-mlogloss:0.46633\tvalid-mlogloss:0.69341                                                                    \n",
      "[700]\ttrain-mlogloss:0.43663\tvalid-mlogloss:0.68596                                                                    \n",
      "[800]\ttrain-mlogloss:0.41279\tvalid-mlogloss:0.68137                                                                    \n",
      "[900]\ttrain-mlogloss:0.39227\tvalid-mlogloss:0.67909                                                                    \n",
      "[1000]\ttrain-mlogloss:0.37555\tvalid-mlogloss:0.67788                                                                   \n",
      "[1093]\ttrain-mlogloss:0.36139\tvalid-mlogloss:0.67758                                                                   \n",
      "fold3 multi_logloss: 0.6775493221671809                                                                                \n",
      "[0]\ttrain-mlogloss:1.09565\tvalid-mlogloss:1.09641                                                                      \n",
      "[100]\ttrain-mlogloss:0.85586\tvalid-mlogloss:0.91813                                                                    \n",
      "[200]\ttrain-mlogloss:0.71156\tvalid-mlogloss:0.82231                                                                    \n",
      "[300]\ttrain-mlogloss:0.61613\tvalid-mlogloss:0.76766                                                                    \n",
      "[400]\ttrain-mlogloss:0.54892\tvalid-mlogloss:0.73611                                                                    \n",
      "[500]\ttrain-mlogloss:0.49971\tvalid-mlogloss:0.71772                                                                    \n",
      "[600]\ttrain-mlogloss:0.46309\tvalid-mlogloss:0.70770                                                                    \n",
      "[700]\ttrain-mlogloss:0.43339\tvalid-mlogloss:0.70234                                                                    \n",
      "[800]\ttrain-mlogloss:0.40941\tvalid-mlogloss:0.69956                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[900]\ttrain-mlogloss:0.38894\tvalid-mlogloss:0.69833                                                                    \n",
      "[1000]\ttrain-mlogloss:0.37250\tvalid-mlogloss:0.69821                                                                   \n",
      "[1007]\ttrain-mlogloss:0.37139\tvalid-mlogloss:0.69818                                                                   \n",
      "fold4 multi_logloss: 0.6981841780043082                                                                                \n",
      "[0]\ttrain-mlogloss:1.09564\tvalid-mlogloss:1.09639                                                                      \n",
      "[100]\ttrain-mlogloss:0.85572\tvalid-mlogloss:0.91932                                                                    \n",
      "[200]\ttrain-mlogloss:0.71128\tvalid-mlogloss:0.82414                                                                    \n",
      "[300]\ttrain-mlogloss:0.61585\tvalid-mlogloss:0.76937                                                                    \n",
      "[400]\ttrain-mlogloss:0.54851\tvalid-mlogloss:0.73706                                                                    \n",
      "[500]\ttrain-mlogloss:0.49922\tvalid-mlogloss:0.71794                                                                    \n",
      "[600]\ttrain-mlogloss:0.46254\tvalid-mlogloss:0.70717                                                                    \n",
      "[700]\ttrain-mlogloss:0.43273\tvalid-mlogloss:0.70061                                                                    \n",
      "[800]\ttrain-mlogloss:0.40898\tvalid-mlogloss:0.69690                                                                    \n",
      "[900]\ttrain-mlogloss:0.38847\tvalid-mlogloss:0.69501                                                                    \n",
      "[1000]\ttrain-mlogloss:0.37183\tvalid-mlogloss:0.69450                                                                   \n",
      "[1010]\ttrain-mlogloss:0.37032\tvalid-mlogloss:0.69450                                                                   \n",
      "fold5 multi_logloss: 0.6944771438895302                                                                                \n",
      "multi_logloss:                                                                                                         \n",
      "0.6918624600654043                                                                                                     \n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bylevel': 0.65, 'colsample_bytree': 0.5, 'eta': 0.004, 'eval_metric': 'mlogloss', 'gamma': 0.7000000000000001, 'max_depth': 100, 'min_child_weight': 2.0, 'num_class': 3, 'objective': 'multi:softprob', 'seed': 0, 'subsample': 0.7000000000000001}\n",
      "[0]\ttrain-mlogloss:1.09587\tvalid-mlogloss:1.09661                                                                      \n",
      "[100]\ttrain-mlogloss:0.87893\tvalid-mlogloss:0.94296                                                                    \n",
      "[200]\ttrain-mlogloss:0.73566\tvalid-mlogloss:0.85037                                                                    \n",
      "[300]\ttrain-mlogloss:0.63608\tvalid-mlogloss:0.79332                                                                    \n",
      "[400]\ttrain-mlogloss:0.56360\tvalid-mlogloss:0.75704                                                                    \n",
      "[500]\ttrain-mlogloss:0.50958\tvalid-mlogloss:0.73479                                                                    \n",
      "[600]\ttrain-mlogloss:0.46706\tvalid-mlogloss:0.72079                                                                    \n",
      "[700]\ttrain-mlogloss:0.43459\tvalid-mlogloss:0.71261                                                                    \n",
      "[800]\ttrain-mlogloss:0.40707\tvalid-mlogloss:0.70781                                                                    \n",
      "[900]\ttrain-mlogloss:0.38448\tvalid-mlogloss:0.70559                                                                    \n",
      "[1000]\ttrain-mlogloss:0.36542\tvalid-mlogloss:0.70473                                                                   \n",
      "[1064]\ttrain-mlogloss:0.35462\tvalid-mlogloss:0.70477                                                                   \n",
      "fold1 multi_logloss: 0.7047714462404103                                                                                \n",
      "[0]\ttrain-mlogloss:1.09591\tvalid-mlogloss:1.09662                                                                      \n",
      "[100]\ttrain-mlogloss:0.88118\tvalid-mlogloss:0.93858                                                                    \n",
      "[200]\ttrain-mlogloss:0.73847\tvalid-mlogloss:0.84267                                                                    \n",
      "[300]\ttrain-mlogloss:0.63885\tvalid-mlogloss:0.78282                                                                    \n",
      "[400]\ttrain-mlogloss:0.56607\tvalid-mlogloss:0.74499                                                                    \n",
      "[500]\ttrain-mlogloss:0.51179\tvalid-mlogloss:0.72106                                                                    \n",
      "[600]\ttrain-mlogloss:0.46909\tvalid-mlogloss:0.70596                                                                    \n",
      "[700]\ttrain-mlogloss:0.43629\tvalid-mlogloss:0.69679                                                                    \n",
      "[800]\ttrain-mlogloss:0.40853\tvalid-mlogloss:0.69142                                                                    \n",
      "[900]\ttrain-mlogloss:0.38590\tvalid-mlogloss:0.68870                                                                    \n",
      "[1000]\ttrain-mlogloss:0.36673\tvalid-mlogloss:0.68740                                                                   \n",
      "[1100]\ttrain-mlogloss:0.35019\tvalid-mlogloss:0.68735                                                                   \n",
      "[1113]\ttrain-mlogloss:0.34808\tvalid-mlogloss:0.68742                                                                   \n",
      "fold2 multi_logloss: 0.6874055282695138                                                                                \n",
      "[0]\ttrain-mlogloss:1.09608\tvalid-mlogloss:1.09671                                                                      \n",
      "[100]\ttrain-mlogloss:0.87974\tvalid-mlogloss:0.93793                                                                    \n",
      "[200]\ttrain-mlogloss:0.73820\tvalid-mlogloss:0.84226                                                                    \n",
      "[300]\ttrain-mlogloss:0.63912\tvalid-mlogloss:0.78201                                                                    \n",
      "[400]\ttrain-mlogloss:0.56655\tvalid-mlogloss:0.74323                                                                    \n",
      "[500]\ttrain-mlogloss:0.51201\tvalid-mlogloss:0.71807                                                                    \n",
      "[600]\ttrain-mlogloss:0.47111\tvalid-mlogloss:0.70242                                                                    \n",
      "[700]\ttrain-mlogloss:0.43794\tvalid-mlogloss:0.69247                                                                    \n",
      "[800]\ttrain-mlogloss:0.41130\tvalid-mlogloss:0.68614                                                                    \n",
      "[900]\ttrain-mlogloss:0.38843\tvalid-mlogloss:0.68245                                                                    \n",
      "[1000]\ttrain-mlogloss:0.36984\tvalid-mlogloss:0.68066                                                                   \n",
      "[1100]\ttrain-mlogloss:0.35326\tvalid-mlogloss:0.67988                                                                   \n",
      "[1200]\ttrain-mlogloss:0.33887\tvalid-mlogloss:0.67974                                                                   \n",
      "[1208]\ttrain-mlogloss:0.33784\tvalid-mlogloss:0.67978                                                                   \n",
      "fold3 multi_logloss: 0.679788747266376                                                                                 \n",
      "[0]\ttrain-mlogloss:1.09607\tvalid-mlogloss:1.09677                                                                      \n",
      "[100]\ttrain-mlogloss:0.87845\tvalid-mlogloss:0.94025                                                                    \n",
      "[200]\ttrain-mlogloss:0.73618\tvalid-mlogloss:0.84747                                                                    \n",
      "[300]\ttrain-mlogloss:0.63662\tvalid-mlogloss:0.78938                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[400]\ttrain-mlogloss:0.56379\tvalid-mlogloss:0.75304                                                                    \n",
      "[500]\ttrain-mlogloss:0.50921\tvalid-mlogloss:0.72992                                                                    \n",
      "[600]\ttrain-mlogloss:0.46826\tvalid-mlogloss:0.71640                                                                    \n",
      "[700]\ttrain-mlogloss:0.43506\tvalid-mlogloss:0.70837                                                                    \n",
      "[800]\ttrain-mlogloss:0.40828\tvalid-mlogloss:0.70371                                                                    \n",
      "[900]\ttrain-mlogloss:0.38536\tvalid-mlogloss:0.70106                                                                    \n",
      "[1000]\ttrain-mlogloss:0.36693\tvalid-mlogloss:0.70016                                                                   \n",
      "[1012]\ttrain-mlogloss:0.36483\tvalid-mlogloss:0.70017                                                                   \n",
      "fold4 multi_logloss: 0.7001646000850354                                                                                \n",
      "[0]\ttrain-mlogloss:1.09604\tvalid-mlogloss:1.09676                                                                      \n",
      "[100]\ttrain-mlogloss:0.87835\tvalid-mlogloss:0.94191                                                                    \n",
      "[200]\ttrain-mlogloss:0.73592\tvalid-mlogloss:0.84947                                                                    \n",
      "[300]\ttrain-mlogloss:0.63628\tvalid-mlogloss:0.79135                                                                    \n",
      "[400]\ttrain-mlogloss:0.56324\tvalid-mlogloss:0.75454                                                                    \n",
      "[500]\ttrain-mlogloss:0.50828\tvalid-mlogloss:0.73101                                                                    \n",
      "[600]\ttrain-mlogloss:0.46711\tvalid-mlogloss:0.71670                                                                    \n",
      "[700]\ttrain-mlogloss:0.43382\tvalid-mlogloss:0.70766                                                                    \n",
      "[800]\ttrain-mlogloss:0.40709\tvalid-mlogloss:0.70225                                                                    \n",
      "[900]\ttrain-mlogloss:0.38427\tvalid-mlogloss:0.69899                                                                    \n",
      "[1000]\ttrain-mlogloss:0.36578\tvalid-mlogloss:0.69739                                                                   \n",
      "[1100]\ttrain-mlogloss:0.34932\tvalid-mlogloss:0.69704                                                                   \n",
      "[1123]\ttrain-mlogloss:0.34585\tvalid-mlogloss:0.69701                                                                   \n",
      "fold5 multi_logloss: 0.6970132236405012                                                                                \n",
      "multi_logloss:                                                                                                         \n",
      "0.6938288799268523                                                                                                     \n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bylevel': 0.45, 'colsample_bytree': 0.35000000000000003, 'eta': 0.005, 'eval_metric': 'mlogloss', 'gamma': 0.6000000000000001, 'max_depth': 100, 'min_child_weight': 3.0, 'num_class': 3, 'objective': 'multi:softprob', 'seed': 0, 'subsample': 0.65}\n",
      "[0]\ttrain-mlogloss:1.09560\tvalid-mlogloss:1.09626                                                                      \n",
      "[100]\ttrain-mlogloss:0.87361\tvalid-mlogloss:0.92912                                                                    \n",
      "[200]\ttrain-mlogloss:0.73766\tvalid-mlogloss:0.83767                                                                    \n",
      "[300]\ttrain-mlogloss:0.64712\tvalid-mlogloss:0.78475                                                                    \n",
      "[400]\ttrain-mlogloss:0.58208\tvalid-mlogloss:0.75272                                                                    \n",
      "[500]\ttrain-mlogloss:0.53531\tvalid-mlogloss:0.73372                                                                    \n",
      "[600]\ttrain-mlogloss:0.49763\tvalid-mlogloss:0.72174                                                                    \n",
      "[700]\ttrain-mlogloss:0.46835\tvalid-mlogloss:0.71446                                                                    \n",
      "[800]\ttrain-mlogloss:0.44232\tvalid-mlogloss:0.70915                                                                    \n",
      "[900]\ttrain-mlogloss:0.42134\tvalid-mlogloss:0.70640                                                                    \n",
      "[1000]\ttrain-mlogloss:0.40368\tvalid-mlogloss:0.70500                                                                   \n",
      "[1100]\ttrain-mlogloss:0.38810\tvalid-mlogloss:0.70446                                                                   \n",
      "[1114]\ttrain-mlogloss:0.38592\tvalid-mlogloss:0.70440                                                                   \n",
      "fold1 multi_logloss: 0.7044180769839713                                                                                \n",
      "[0]\ttrain-mlogloss:1.09565\tvalid-mlogloss:1.09623                                                                      \n",
      "[100]\ttrain-mlogloss:0.87632\tvalid-mlogloss:0.92425                                                                    \n",
      "[200]\ttrain-mlogloss:0.74127\tvalid-mlogloss:0.82900                                                                    \n",
      "[300]\ttrain-mlogloss:0.65089\tvalid-mlogloss:0.77298                                                                    \n",
      "[400]\ttrain-mlogloss:0.58583\tvalid-mlogloss:0.73867                                                                    \n",
      "[500]\ttrain-mlogloss:0.53872\tvalid-mlogloss:0.71800                                                                    \n",
      "[600]\ttrain-mlogloss:0.50072\tvalid-mlogloss:0.70505                                                                    \n",
      "[700]\ttrain-mlogloss:0.47112\tvalid-mlogloss:0.69665                                                                    \n",
      "[800]\ttrain-mlogloss:0.44483\tvalid-mlogloss:0.69115                                                                    \n",
      "[900]\ttrain-mlogloss:0.42372\tvalid-mlogloss:0.68791                                                                    \n",
      "[1000]\ttrain-mlogloss:0.40601\tvalid-mlogloss:0.68617                                                                   \n",
      "[1100]\ttrain-mlogloss:0.39027\tvalid-mlogloss:0.68560                                                                   \n",
      "[1162]\ttrain-mlogloss:0.38114\tvalid-mlogloss:0.68542                                                                   \n",
      "fold2 multi_logloss: 0.6854563984355202                                                                                \n",
      "[0]\ttrain-mlogloss:1.09603\tvalid-mlogloss:1.09654                                                                      \n",
      "[100]\ttrain-mlogloss:0.87612\tvalid-mlogloss:0.92497                                                                    \n",
      "[200]\ttrain-mlogloss:0.74344\tvalid-mlogloss:0.83128                                                                    \n",
      "[300]\ttrain-mlogloss:0.65381\tvalid-mlogloss:0.77522                                                                    \n",
      "[400]\ttrain-mlogloss:0.58900\tvalid-mlogloss:0.74045                                                                    \n",
      "[500]\ttrain-mlogloss:0.54029\tvalid-mlogloss:0.71783                                                                    \n",
      "[600]\ttrain-mlogloss:0.50362\tvalid-mlogloss:0.70372                                                                    \n",
      "[700]\ttrain-mlogloss:0.47387\tvalid-mlogloss:0.69448                                                                    \n",
      "[800]\ttrain-mlogloss:0.44983\tvalid-mlogloss:0.68822                                                                    \n",
      "[900]\ttrain-mlogloss:0.42861\tvalid-mlogloss:0.68382                                                                    \n",
      "[1000]\ttrain-mlogloss:0.41128\tvalid-mlogloss:0.68141                                                                   \n",
      "[1100]\ttrain-mlogloss:0.39536\tvalid-mlogloss:0.67965                                                                   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1200]\ttrain-mlogloss:0.38145\tvalid-mlogloss:0.67887                                                                   \n",
      "[1300]\ttrain-mlogloss:0.36911\tvalid-mlogloss:0.67836                                                                   \n",
      "[1400]\ttrain-mlogloss:0.35703\tvalid-mlogloss:0.67826                                                                   \n",
      "fold3 multi_logloss: 0.6782547007860229                                                                                \n",
      "[0]\ttrain-mlogloss:1.09596\tvalid-mlogloss:1.09652                                                                      \n",
      "[100]\ttrain-mlogloss:0.87463\tvalid-mlogloss:0.92713                                                                    \n",
      "[200]\ttrain-mlogloss:0.74121\tvalid-mlogloss:0.83588                                                                    \n",
      "[300]\ttrain-mlogloss:0.65096\tvalid-mlogloss:0.78176                                                                    \n",
      "[400]\ttrain-mlogloss:0.58591\tvalid-mlogloss:0.74926                                                                    \n",
      "[500]\ttrain-mlogloss:0.53705\tvalid-mlogloss:0.72861                                                                    \n",
      "[600]\ttrain-mlogloss:0.50035\tvalid-mlogloss:0.71654                                                                    \n",
      "[700]\ttrain-mlogloss:0.47062\tvalid-mlogloss:0.70892                                                                    \n",
      "[800]\ttrain-mlogloss:0.44649\tvalid-mlogloss:0.70434                                                                    \n",
      "[900]\ttrain-mlogloss:0.42528\tvalid-mlogloss:0.70116                                                                    \n",
      "[1000]\ttrain-mlogloss:0.40791\tvalid-mlogloss:0.69971                                                                   \n",
      "[1100]\ttrain-mlogloss:0.39199\tvalid-mlogloss:0.69896                                                                   \n",
      "[1187]\ttrain-mlogloss:0.37998\tvalid-mlogloss:0.69887                                                                   \n",
      "fold4 multi_logloss: 0.698892319381489                                                                                 \n",
      "[0]\ttrain-mlogloss:1.09593\tvalid-mlogloss:1.09652                                                                      \n",
      "[100]\ttrain-mlogloss:0.87452\tvalid-mlogloss:0.92846                                                                    \n",
      "[200]\ttrain-mlogloss:0.74122\tvalid-mlogloss:0.83823                                                                    \n",
      "[300]\ttrain-mlogloss:0.65078\tvalid-mlogloss:0.78459                                                                    \n",
      "[400]\ttrain-mlogloss:0.58564\tvalid-mlogloss:0.75163                                                                    \n",
      "[500]\ttrain-mlogloss:0.53671\tvalid-mlogloss:0.73054                                                                    \n",
      "[600]\ttrain-mlogloss:0.49997\tvalid-mlogloss:0.71792                                                                    \n",
      "[700]\ttrain-mlogloss:0.47009\tvalid-mlogloss:0.70987                                                                    \n",
      "[800]\ttrain-mlogloss:0.44590\tvalid-mlogloss:0.70470                                                                    \n",
      "[900]\ttrain-mlogloss:0.42466\tvalid-mlogloss:0.70094                                                                    \n",
      "[1000]\ttrain-mlogloss:0.40731\tvalid-mlogloss:0.69893                                                                   \n",
      "[1100]\ttrain-mlogloss:0.39142\tvalid-mlogloss:0.69779                                                                   \n",
      "[1187]\ttrain-mlogloss:0.37945\tvalid-mlogloss:0.69730                                                                   \n",
      "fold5 multi_logloss: 0.697305340663935                                                                                 \n",
      "multi_logloss:                                                                                                         \n",
      "0.6928655238719105                                                                                                     \n",
      "Training with params:                                                                                                  \n",
      "{'colsample_bylevel': 0.5, 'colsample_bytree': 0.6000000000000001, 'eta': 0.004, 'eval_metric': 'mlogloss', 'gamma': 0.6000000000000001, 'max_depth': 100, 'min_child_weight': 2.0, 'num_class': 3, 'objective': 'multi:softprob', 'seed': 0, 'subsample': 0.75}\n",
      "[0]\ttrain-mlogloss:1.09579\tvalid-mlogloss:1.09656                                                                      \n",
      "[100]\ttrain-mlogloss:0.87127\tvalid-mlogloss:0.93905                                                                    \n",
      "[200]\ttrain-mlogloss:0.72290\tvalid-mlogloss:0.84440                                                                    \n",
      "[300]\ttrain-mlogloss:0.62018\tvalid-mlogloss:0.78677                                                                    \n",
      "[400]\ttrain-mlogloss:0.54579\tvalid-mlogloss:0.75092                                                                    \n",
      "[500]\ttrain-mlogloss:0.48964\tvalid-mlogloss:0.72909                                                                    \n",
      "[600]\ttrain-mlogloss:0.44528\tvalid-mlogloss:0.71602                                                                    \n",
      "[700]\ttrain-mlogloss:0.41074\tvalid-mlogloss:0.70865                                                                    \n",
      "[800]\ttrain-mlogloss:0.38239\tvalid-mlogloss:0.70514                                                                    \n",
      "[900]\ttrain-mlogloss:0.35872\tvalid-mlogloss:0.70393                                                                    \n",
      "[949]\ttrain-mlogloss:0.34893\tvalid-mlogloss:0.70393                                                                    \n",
      "fold1 multi_logloss: 0.7039307196716423                                                                                \n",
      "[0]\ttrain-mlogloss:1.09583\tvalid-mlogloss:1.09654                                                                      \n",
      "[100]\ttrain-mlogloss:0.87337\tvalid-mlogloss:0.93433                                                                    \n",
      "[200]\ttrain-mlogloss:0.72547\tvalid-mlogloss:0.83640                                                                    \n",
      "[300]\ttrain-mlogloss:0.62275\tvalid-mlogloss:0.77571                                                                    \n",
      "[400]\ttrain-mlogloss:0.54793\tvalid-mlogloss:0.73808                                                                    \n",
      "[500]\ttrain-mlogloss:0.49175\tvalid-mlogloss:0.71499                                                                    \n",
      "[600]\ttrain-mlogloss:0.44723\tvalid-mlogloss:0.70097                                                                    \n",
      "[700]\ttrain-mlogloss:0.41254\tvalid-mlogloss:0.69264                                                                    \n",
      "[800]\ttrain-mlogloss:0.38406\tvalid-mlogloss:0.68856                                                                    \n",
      "[900]\ttrain-mlogloss:0.36033\tvalid-mlogloss:0.68719                                                                    \n",
      "[940]\ttrain-mlogloss:0.35236\tvalid-mlogloss:0.68722                                                                    \n",
      "fold2 multi_logloss: 0.6872222758890902                                                                                \n",
      "[0]\ttrain-mlogloss:1.09584\tvalid-mlogloss:1.09654                                                                      \n",
      "[100]\ttrain-mlogloss:0.87212\tvalid-mlogloss:0.93393                                                                    \n",
      "[200]\ttrain-mlogloss:0.72539\tvalid-mlogloss:0.83635                                                                    \n",
      "[300]\ttrain-mlogloss:0.62264\tvalid-mlogloss:0.77512                                                                    \n",
      "[400]\ttrain-mlogloss:0.54815\tvalid-mlogloss:0.73684                                                                    \n",
      "[500]\ttrain-mlogloss:0.49195\tvalid-mlogloss:0.71249                                                                    \n",
      "[600]\ttrain-mlogloss:0.44950\tvalid-mlogloss:0.69740                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[700]\ttrain-mlogloss:0.41551\tvalid-mlogloss:0.68837                                                                    \n",
      "[800]\ttrain-mlogloss:0.38745\tvalid-mlogloss:0.68303                                                                    \n",
      "[900]\ttrain-mlogloss:0.36410\tvalid-mlogloss:0.68068                                                                    \n",
      "[1000]\ttrain-mlogloss:0.34507\tvalid-mlogloss:0.67990                                                                   \n",
      "[1052]\ttrain-mlogloss:0.33614\tvalid-mlogloss:0.68003                                                                   \n",
      "fold3 multi_logloss: 0.6800381507338001                                                                                \n",
      "[0]\ttrain-mlogloss:1.09583\tvalid-mlogloss:1.09658                                                                      \n",
      "[100]\ttrain-mlogloss:0.87081\tvalid-mlogloss:0.93661                                                                    \n",
      "[200]\ttrain-mlogloss:0.72316\tvalid-mlogloss:0.84188                                                                    \n",
      "[300]\ttrain-mlogloss:0.62009\tvalid-mlogloss:0.78313                                                                    \n",
      "[400]\ttrain-mlogloss:0.54556\tvalid-mlogloss:0.74683                                                                    \n",
      "[500]\ttrain-mlogloss:0.48931\tvalid-mlogloss:0.72464                                                                    \n",
      "[600]\ttrain-mlogloss:0.44671\tvalid-mlogloss:0.71191                                                                    \n",
      "[700]\ttrain-mlogloss:0.41264\tvalid-mlogloss:0.70474                                                                    \n",
      "[800]\ttrain-mlogloss:0.38444\tvalid-mlogloss:0.70115                                                                    \n",
      "[900]\ttrain-mlogloss:0.36129\tvalid-mlogloss:0.69989                                                                    \n",
      "[930]\ttrain-mlogloss:0.35532\tvalid-mlogloss:0.69989                                                                    \n",
      "fold4 multi_logloss: 0.6998858720149741                                                                                \n",
      "[0]\ttrain-mlogloss:1.09583\tvalid-mlogloss:1.09661                                                                      \n",
      "[100]\ttrain-mlogloss:0.87058\tvalid-mlogloss:0.93790                                                                    \n",
      "[200]\ttrain-mlogloss:0.72278\tvalid-mlogloss:0.84320                                                                    \n",
      "[300]\ttrain-mlogloss:0.61949\tvalid-mlogloss:0.78414                                                                    \n",
      "[400]\ttrain-mlogloss:0.54479\tvalid-mlogloss:0.74757                                                                    \n",
      "[500]\ttrain-mlogloss:0.48831\tvalid-mlogloss:0.72455                                                                    \n",
      "[600]\ttrain-mlogloss:0.44565\tvalid-mlogloss:0.71106                                                                    \n",
      "[700]\ttrain-mlogloss:0.41151\tvalid-mlogloss:0.70283                                                                    \n",
      "[800]\ttrain-mlogloss:0.38345\tvalid-mlogloss:0.69873                                                                    \n",
      "[900]\ttrain-mlogloss:0.36028\tvalid-mlogloss:0.69654                                                                    \n",
      "[985]\ttrain-mlogloss:0.34386\tvalid-mlogloss:0.69612                                                                    \n",
      "fold5 multi_logloss: 0.6961258077677612                                                                                \n",
      "multi_logloss:                                                                                                         \n",
      "0.6934407266799102                                                                                                     \n",
      "100%|█████████████████████████████████████████████| 10/10 [2:21:49<00:00, 850.98s/trial, best loss: 0.6913250815472309]\n",
      "The best hyperparameters are:  \n",
      "\n",
      "{'colsample_bylevel': 0.4, 'colsample_bytree': 0.45, 'eta': 0.005, 'gamma': 0.7000000000000001, 'min_child_weight': 3.0, 'subsample': 0.65}\n"
     ]
    }
   ],
   "source": [
    "SEED=0\n",
    "\n",
    "# Hyperopt의 metric함수를 StratifiedKFold(cv=5)로 구하기\n",
    "def score(params):\n",
    "    print(\"Training with params: \")\n",
    "    print(params)\n",
    "    \n",
    "    kfold = StratifiedKFold(n_splits=5, random_state = SEED, shuffle = True)\n",
    "    cv = np.zeros((train_x.shape[0], 3))\n",
    "\n",
    "    for n, (train_idx, val_idx) in enumerate(kfold.split(train_x, train_y)):\n",
    "        \n",
    "        x_train, x_val = train_x.iloc[train_idx], train_x.iloc[val_idx]\n",
    "        y_train, y_val = train_y.iloc[train_idx], train_y.iloc[val_idx]\n",
    "        \n",
    "        dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "        dvalid = xgb.DMatrix(x_val, label=y_val)\n",
    "        watchlist = [(dtrain, 'train'), (dvalid, 'valid')]\n",
    "\n",
    "        xgbmodel = xgb.train(params, dtrain, 100000, watchlist, early_stopping_rounds=30, verbose_eval=100)\n",
    "        cv[val_idx, :] = xgbmodel.predict(dvalid)\n",
    "        print(f'fold{n+1} multi_logloss: {log_loss(y_val, cv[val_idx, :])}')\n",
    "    print('multi_logloss:', log_loss(train_y, cv))\n",
    "    score = log_loss(train_y, cv)\n",
    "    return {'loss': score, 'status': STATUS_OK}\n",
    "\n",
    "# Hyperopt의 범위를 지정해주고 max_evals만큼 반복한 후 최적의 파라미터를 반환\n",
    "def optimize(random_state=SEED):\n",
    "    \n",
    "\n",
    "    space = {\n",
    "        'eta': hp.quniform('eta', 0.003, 0.006, 0.001),\n",
    "        'min_child_weight': hp.quniform('min_child_weight', 1, 3, 1),\n",
    "        'subsample': hp.quniform('subsample', 0.6, 0.8, 0.05),\n",
    "        'gamma': hp.quniform('gamma', 0.6, 0.8, 0.05),\n",
    "        'colsample_bytree': hp.quniform('colsample_bytree', 0.3, 0.7, 0.05),\n",
    "        'colsample_bylevel': hp.quniform('colsample_bylevel', 0.3, 0.7, 0.05),\n",
    "        'max_depth' : 100,\n",
    "        'eval_metric': 'mlogloss',\n",
    "        'objective' : 'multi:softprob',\n",
    "        'num_class' : 3,\n",
    "        'seed': SEED,\n",
    "    }\n",
    "    # Use the fmin function from Hyperopt to find the best hyperparameters\n",
    "    best = fmin(score, space, algo=tpe.suggest, \n",
    "                # trials=trials, \n",
    "                max_evals=10)\n",
    "    return best\n",
    "\n",
    "best_hyperparams = optimize()\n",
    "print(\"The best hyperparameters are: \", \"\\n\")\n",
    "print(best_hyperparams)\n",
    "params = best_hyperparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 seeds x 5 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T14:26:28.637607Z",
     "start_time": "2021-05-16T14:25:49.848336Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:1.09663\tvalid-mlogloss:1.09709\n",
      "[100]\ttrain-mlogloss:0.93188\tvalid-mlogloss:0.97316\n",
      "[200]\ttrain-mlogloss:0.81391\tvalid-mlogloss:0.88909\n",
      "[300]\ttrain-mlogloss:0.72460\tvalid-mlogloss:0.82886\n",
      "[400]\ttrain-mlogloss:0.65734\tvalid-mlogloss:0.78663\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-3015adb7861b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m          \u001b[1;34m'gamma'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m0.7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'max_depth'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'min_child_weight'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m2.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'num_class'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m          'objective': 'multi:softprob', 'seed': 0, 'subsample': 0.7}\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mxgbmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwatchlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[1;31m#joblib.dump(xgbmodel, f'./pred_pkl/XGB_{n+1}_fold_{seed}_seed_xgb.pkl')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[0mBooster\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mbooster\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m     \"\"\"\n\u001b[1;32m--> 189\u001b[1;33m     bst = _train_internal(params, dtrain,\n\u001b[0m\u001b[0;32m    190\u001b[0m                           \u001b[0mnum_boost_round\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m                           \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m         \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1497\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1499\u001b[1;33m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0m\u001b[0;32m   1500\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1501\u001b[0m                                                     dtrain.handle))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lucky_seeds=[42, 2019, 91373] # 늘려가면서\n",
    "xgtest = xgb.DMatrix(test_x)\n",
    "for i, seed in enumerate(lucky_seeds):\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=10, random_state = seed, shuffle = True) # 늘려가면서\n",
    "    cv = np.zeros((train.shape[0], 3))\n",
    "    pred_test = np.zeros((test_x.shape[0], 3), dtype=float)\n",
    "\n",
    "    for n, (train_idx, val_idx) in enumerate(kfold.split(train_x, train_y)):\n",
    "        \n",
    "        x_train, x_val = train_x.iloc[train_idx], train_x.iloc[val_idx]\n",
    "        y_train, y_val = train_y.iloc[train_idx], train_y.iloc[val_idx]\n",
    "        \n",
    "        dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "        dvalid = xgb.DMatrix(x_val, label=y_val)\n",
    "        watchlist = [(dtrain, 'train'), (dvalid, 'valid')]\n",
    "\n",
    "        param = params\n",
    "#         {'colsample_bylevel': 0.5, 'colsample_bytree': 0.4, 'eta': 0.003, 'eval_metric': 'mlogloss', \n",
    "#          'gamma': 0.7, 'max_depth': 100, 'min_child_weight': 2.0, 'num_class': 3, \n",
    "#          'objective': 'multi:softprob', 'seed': 0, 'subsample': 0.7}\n",
    "        xgbmodel = xgb.train(param, dtrain, 100000, watchlist, early_stopping_rounds=30, verbose_eval=100)\n",
    "        #joblib.dump(xgbmodel, f'./pred_pkl/XGB_{n+1}_fold_{seed}_seed_xgb.pkl')\n",
    "\n",
    "        cv[val_idx, :] = xgbmodel.predict(dvalid)\n",
    "        print(f'fold{n+1} multi_logloss: {log_loss(y_val, cv[val_idx, :])}')\n",
    "        pred_test += xgbmodel.predict(xgtest) / 10 # CV 바꾸면 이 숫자도 똑같이 바꿔야함\n",
    "        \n",
    "    pred_dict['xgb'+str(i+1)] = cv\n",
    "    pred_test_dict['xgb'+str(i+1)] = pred_test\n",
    "    print('multi_logloss:', log_loss(train_y, cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xgbmodels_path = os.listdir('./pred_pkl/')\n",
    "xgbmodels_list = [x for x in xgbmodels_path if x.endswith(\"xgb.pkl\")]\n",
    "assert len(xgbmodels_list) == 15\n",
    "xgb_preds = np.zeros((test_x.shape[0], 3))\n",
    "xgtest = xgb.DMatrix(test_X)\n",
    "\n",
    "for m in xgbmodels_list:\n",
    "    xgbmodel = joblib.load('./pred_pkl/'+m)\n",
    "    xgb_preds_proba = xgbmodel.predict_proba(xgtest\n",
    "       xgb_preds += xgb_preds_proba/15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "params = {'max_depth': [55, 60, 65] # 튜닝할 파라미터 삽입\n",
    "            }\n",
    "\n",
    "rf_clf = RandomForestClassifier(random_state = 0, n_estimators = 1000, \n",
    "                                min_samples_leaf=2, min_samples_split=2,\n",
    "                                criterion='entropy', n_jobs = -1)\n",
    "grid_cv = GridSearchCV(rf_clf, param_grid = params, cv = 5, n_jobs = -1)\n",
    "grid_cv.fit(df_train, y)\n",
    "\n",
    "print('최적 하이퍼 파라미터: ', grid_cv.best_params_)\n",
    "print('최고 예측 정확도: {:.4f}'.format(grid_cv.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 seeds, 5 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lucky_seeds=[42,2019,91373,53,1] # 늘려가면서\n",
    "for i, seed in enumerate(lucky_seeds):\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=10, random_state = seed, shuffle = True) # 늘려가면서\n",
    "    cv = np.zeros((train_x.shape[0], 3))\n",
    "    pred_test = np.zeros((test_x.shape[0], 3), dtype=float)\n",
    "    \n",
    "    for n, (train_idx, val_idx) in enumerate(kfold.split(train_x, train_y)):\n",
    "        \n",
    "        x_train, x_val = train_x.iloc[train_idx], train_x.iloc[val_idx]\n",
    "        y_train, y_val = train_y.iloc[train_idx], train_y.iloc[val_idx]\n",
    "\n",
    "        rfmodel = RandomForestClassifier(n_estimators=1200, criterion='entropy', max_depth=60,\n",
    "                                         min_samples_leaf=2, min_samples_split=2,\n",
    "                                         random_state=seed)\n",
    "        rfmodel.fit(x_train, y_train)\n",
    "        #joblib.dump(rfmodel, f'./pred_pkl/RF_{n+1}_fold_{seed}_seed_rf.pkl')\n",
    "        \n",
    "        cv[val_idx, :] = rfmodel.predict_proba(x_val)      \n",
    "        print(f'fold{n+1} multi_logloss: {log_loss(y_val, cv[val_idx, :])}')\n",
    "        pred_test += rfmodel.predict_proba(test_x) / 10 # CV 바꾸면 이 숫자도 똑같이 바꿔야함\n",
    "        \n",
    "    pred_dict['rf'+str(i+1)] = cv\n",
    "    pred_test_dict['rf'+str(i+1)] = pred_test\n",
    "    print('multi_logloss :', log_loss(train_y, cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rfmodels_path = os.listdir('./pred_pkl/')\n",
    "rfmodels_list = [x for x in rfmodels_path if x.endswith(\"rf.pkl\")]\n",
    "assert len(rfmodels_list) == 15\n",
    "rf_preds = np.zeros((test_x.shape[0], 3))\n",
    "\n",
    "for m in rfmodels_list:\n",
    "    rfmodel = joblib.load('./pred_pkl/'+m)\n",
    "    rf_preds_proba = rfmodel.predict_proba(test_x)\n",
    "    rf_preds += rf_preds_proba/15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) Catboost (성능X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lucky_seeds=[42,2019,91373]\n",
    "for i, seed in enumerate(lucky_seeds):\n",
    "\n",
    "    kfold = KFold(n_splits=5, random_state = seed, shuffle = True)\n",
    "    cv = np.zeros((train.shape[0], 3))\n",
    "    pred_test = np.zeros((test_x.shape[0], 3), dtype=float)\n",
    "    \n",
    "    for n, (train_idx, val_idx) in enumerate(kfold.split(train)):\n",
    "        \n",
    "        x_train, x_val = train_x.iloc[train_idx], train_x.iloc[val_idx]\n",
    "        y_train, y_val = train_y.iloc[train_idx], train_y.iloc[val_idx]\n",
    "        _train = Pool(x_train, label=y_train)\n",
    "        _valid = Pool(x_val, label=y_val)\n",
    "\n",
    "        catmodel =  CatBoostClassifier(loss_function='MultiClass', early_stopping_rounds=50, \n",
    "                                       random_state=seed, learning_rate=0.02, iterations=100000\n",
    "                                       #task_type=\"GPU\"\n",
    "                                      )\n",
    "        \n",
    "        catmodel.fit(_train, eval_set=_valid, use_best_model=True, verbose=2000)\n",
    "        #joblib.dump(rfmodel, f'./pred_pkl/RF_{n+1}_fold_{seed}_seed_rf.pkl')\n",
    "        \n",
    "        cv[val_idx, :] = catmodel.predict_proba(x_val)        \n",
    "        pred_test += catmodel.predict_proba(test_x) / 5\n",
    "        \n",
    "    pred_dict['cat'+str(i+1)] = cv\n",
    "    pred_test_dict['cat'+str(i+1)] = pred_test\n",
    "    print('multi_logloss :', log_loss(true, cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) Stacking (AutoLGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 27features = 3seed(42, 2019, 91373) x 3model(lgb, xgb, rf) x 3class(0, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(np.hstack([x for _, x in pred_dict.items()]))\n",
    "X_test = pd.DataFrame(np.hstack([x for _, x in pred_test_dict.items()]))\n",
    "\n",
    "pred = np.zeros((X_train.shape[0], 3), dtype=float)\n",
    "pred_test = np.zeros((X_test.shape[0], 3), dtype=float)\n",
    "#kfold = KFold(n_splits=5, random_state = seed, shuffle = True)\n",
    "cv = StratifiedKFold(n_splits=4, shuffle=True, random_state=42) # 이건 CV 너무 크게하면 안됨, 3~6까지 테스트해보면 좋을듯\n",
    "\n",
    "for i_cv, (i_trn, i_val) in enumerate(cv.split(X_train, train_y)):\n",
    "    if i_cv == 0:\n",
    "        clf = AutoLGB(objective='multiclass', metric='multi_logloss', params={'num_class': 3}, \n",
    "                      feature_selection=False, n_est=10000)\n",
    "        clf.tune(X_train.iloc[i_trn], train_y[i_trn])\n",
    "        n_best = clf.n_best\n",
    "        features = clf.features\n",
    "        params = clf.params\n",
    "        print(f'best iteration: {n_best}')\n",
    "        print(f'selected features ({len(features)}): {features}')        \n",
    "        print(params)\n",
    "        clf.fit(X_train.iloc[i_trn], train_y[i_trn])\n",
    "    else:\n",
    "        train_data = lgb.Dataset(X_train[features].iloc[i_trn], label=train_y[i_trn])\n",
    "        clf = lgb.train(params, train_data, n_best, verbose_eval=100)\n",
    "    \n",
    "    pred[i_val] = clf.predict(X_train[features].iloc[i_val])\n",
    "    pred_test += clf.predict(X_test[features]) / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T14:30:21.694306Z",
     "start_time": "2021-05-16T14:30:21.688317Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_dict.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'CV Log Loss: {log_loss(train_y, pred):.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 결과 제출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = sample_submission.copy()\n",
    "submission.iloc[:, 1:] = pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission/submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
