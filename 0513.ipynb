{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e515013a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import glob\n",
    "import os\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "from catboost import Pool, CatBoostClassifier\n",
    "from kaggler.model import AutoLGB\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, GridSearchCV, StratifiedShuffleSplit, train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, log_loss\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db463649",
   "metadata": {},
   "source": [
    "# 1. 문제 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b57cb5",
   "metadata": {},
   "source": [
    "# 2. 데이터 수집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c78c0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8fbbe7bc",
   "metadata": {},
   "source": [
    "## (1) 데이콘 기본 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c526372c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv').drop(['index'], axis=1).fillna('NAN')\n",
    "test = pd.read_csv('data/test.csv').drop(['index'], axis=1).fillna('NAN')\n",
    "sample_submission = pd.read_csv('data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35e15bd",
   "metadata": {},
   "source": [
    "# 4. 탐색적 데이터 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8702ae4c",
   "metadata": {},
   "source": [
    "# 5. 변수 조정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf2fc42",
   "metadata": {},
   "source": [
    "## (1) 이상치 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80a66380",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_col = []\n",
    "for col in train.columns:\n",
    "    if (train[col].dtype == 'O'):\n",
    "        object_col.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4ab12a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder()\n",
    "enc.fit(train.loc[:,object_col])\n",
    "\n",
    "train_onehot_df = pd.DataFrame(enc.transform(train.loc[:, object_col]).toarray(), \n",
    "                               columns=enc.get_feature_names(object_col))\n",
    "train.drop(object_col, axis=1, inplace=True)\n",
    "train = pd.concat([train, train_onehot_df], axis=1)\n",
    "\n",
    "test_onehot_df = pd.DataFrame(enc.transform(test.loc[:, object_col]).toarray(),\n",
    "                              columns=enc.get_feature_names(object_col))\n",
    "test.drop(object_col, axis=1, inplace=True)\n",
    "test = pd.concat([test, test_onehot_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f471ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DAYS_BIRTH\n",
    "train['DAYS_BIRTH_month']=np.floor((-train['DAYS_BIRTH'])/30)-(\n",
    "    (np.floor((-train['DAYS_BIRTH'])/30)/12).astype(int)*12)\n",
    "train['DAYS_BIRTH_week']=np.floor((-train['DAYS_BIRTH'])/7)-(\n",
    "    (np.floor((-train['DAYS_BIRTH'])/7)/4).astype(int)*4)\n",
    "\n",
    "# DAYS_EMPLOYED\n",
    "train['DAYS_EMPLOYED_month']=np.floor((-train['DAYS_EMPLOYED'])/30)-(\n",
    "    (np.floor((-train['DAYS_EMPLOYED'])/30)/12).astype(int)*12)\n",
    "train['DAYS_EMPLOYED_week']=np.floor((-train['DAYS_EMPLOYED'])/7)-(\n",
    "    (np.floor((-train['DAYS_EMPLOYED'])/7)/4).astype(int)*4)\n",
    "\n",
    "# before_EMPLOYED\n",
    "train['before_EMPLOYED']=train['DAYS_BIRTH']-train['DAYS_EMPLOYED']\n",
    "train['before_EMPLOYED_month']=np.floor((-train['before_EMPLOYED'])/30)-(\n",
    "    (np.floor((-train['before_EMPLOYED'])/30)/12).astype(int)*12)\n",
    "train['before_EMPLOYED_week']=np.floor((-train['before_EMPLOYED'])/7)-(\n",
    "    (np.floor((-train['before_EMPLOYED'])/7)/4).astype(int)*4)\n",
    "\n",
    "# DAYS_BIRTH\n",
    "test['DAYS_BIRTH_month']=np.floor((-test['DAYS_BIRTH'])/30)-(\n",
    "    (np.floor((-test['DAYS_BIRTH'])/30)/12).astype(int)*12)\n",
    "test['DAYS_BIRTH_week']=np.floor((-test['DAYS_BIRTH'])/7)-(\n",
    "    (np.floor((-test['DAYS_BIRTH'])/7)/4).astype(int)*4)\n",
    "\n",
    "# DAYS_EMPLOYED\n",
    "test['DAYS_EMPLOYED_month']=np.floor((-test['DAYS_EMPLOYED'])/30)-(\n",
    "    (np.floor((-test['DAYS_EMPLOYED'])/30)/12).astype(int)*12)\n",
    "test['DAYS_EMPLOYED_week']=np.floor((-test['DAYS_EMPLOYED'])/7)-(\n",
    "    (np.floor((-test['DAYS_EMPLOYED'])/7)/4).astype(int)*4)\n",
    "\n",
    "# before_EMPLOYED\n",
    "test['before_EMPLOYED']=test['DAYS_BIRTH']-test['DAYS_EMPLOYED']\n",
    "test['before_EMPLOYED_month']=np.floor((-test['before_EMPLOYED'])/30)-(\n",
    "    (np.floor((-test['before_EMPLOYED'])/30)/12).astype(int)*12)\n",
    "test['before_EMPLOYED_week']=np.floor((-test['before_EMPLOYED'])/7)-(\n",
    "    (np.floor((-test['before_EMPLOYED'])/7)/4).astype(int)*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ae58425",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 아이의 수가 7명 이상인 데이터 제거\n",
    "train = train[train['child_num']<=6].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d29608f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 총 수익 skewed data 처리\n",
    "train['log_income_total'] = np.log(train['income_total'])\n",
    "train['sqrt_income_total'] = np.sqrt(train['income_total'])\n",
    "train['boxcox_income_total'] = stats.boxcox(train['income_total'])[0]\n",
    "test['log_income_total'] = np.log(test['income_total'])\n",
    "test['sqrt_income_total'] = np.sqrt(test['income_total'])\n",
    "test['boxcox_income_total'] = stats.boxcox(test['income_total'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bdd29f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>occyp_type_Cooking staff</th>\n",
       "      <th>occyp_type_Core staff</th>\n",
       "      <th>occyp_type_Drivers</th>\n",
       "      <th>occyp_type_HR staff</th>\n",
       "      <th>occyp_type_High skill tech staff</th>\n",
       "      <th>occyp_type_IT staff</th>\n",
       "      <th>occyp_type_Laborers</th>\n",
       "      <th>occyp_type_Low-skill Laborers</th>\n",
       "      <th>occyp_type_Managers</th>\n",
       "      <th>occyp_type_Medicine staff</th>\n",
       "      <th>occyp_type_NAN</th>\n",
       "      <th>occyp_type_Private service staff</th>\n",
       "      <th>occyp_type_Realty agents</th>\n",
       "      <th>occyp_type_Sales staff</th>\n",
       "      <th>occyp_type_Secretaries</th>\n",
       "      <th>occyp_type_Security staff</th>\n",
       "      <th>occyp_type_Waiters/barmen staff</th>\n",
       "      <th>DAYS_BIRTH_month</th>\n",
       "      <th>DAYS_BIRTH_week</th>\n",
       "      <th>DAYS_EMPLOYED_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11221</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6693</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15897</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18051</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10562</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15900</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14699</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1656</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18442</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26451 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       occyp_type_Cooking staff  occyp_type_Core staff  occyp_type_Drivers  \\\n",
       "11221                       0.0                    0.0                 0.0   \n",
       "6693                        0.0                    0.0                 0.0   \n",
       "402                         0.0                    0.0                 0.0   \n",
       "15897                       0.0                    0.0                 0.0   \n",
       "18051                       0.0                    0.0                 0.0   \n",
       "...                         ...                    ...                 ...   \n",
       "10562                       0.0                    0.0                 0.0   \n",
       "15900                       0.0                    0.0                 0.0   \n",
       "14699                       0.0                    0.0                 0.0   \n",
       "1656                        0.0                    0.0                 0.0   \n",
       "18442                       0.0                    0.0                 0.0   \n",
       "\n",
       "       occyp_type_HR staff  occyp_type_High skill tech staff  \\\n",
       "11221                  0.0                               0.0   \n",
       "6693                   0.0                               0.0   \n",
       "402                    0.0                               0.0   \n",
       "15897                  0.0                               0.0   \n",
       "18051                  0.0                               0.0   \n",
       "...                    ...                               ...   \n",
       "10562                  0.0                               0.0   \n",
       "15900                  0.0                               0.0   \n",
       "14699                  0.0                               0.0   \n",
       "1656                   0.0                               0.0   \n",
       "18442                  0.0                               0.0   \n",
       "\n",
       "       occyp_type_IT staff  occyp_type_Laborers  \\\n",
       "11221                  0.0                  0.0   \n",
       "6693                   0.0                  0.0   \n",
       "402                    0.0                  0.0   \n",
       "15897                  0.0                  0.0   \n",
       "18051                  0.0                  0.0   \n",
       "...                    ...                  ...   \n",
       "10562                  0.0                  0.0   \n",
       "15900                  0.0                  0.0   \n",
       "14699                  0.0                  0.0   \n",
       "1656                   0.0                  0.0   \n",
       "18442                  0.0                  0.0   \n",
       "\n",
       "       occyp_type_Low-skill Laborers  occyp_type_Managers  \\\n",
       "11221                            0.0                  0.0   \n",
       "6693                             0.0                  1.0   \n",
       "402                              0.0                  0.0   \n",
       "15897                            0.0                  0.0   \n",
       "18051                            0.0                  0.0   \n",
       "...                              ...                  ...   \n",
       "10562                            0.0                  1.0   \n",
       "15900                            0.0                  1.0   \n",
       "14699                            0.0                  1.0   \n",
       "1656                             0.0                  1.0   \n",
       "18442                            0.0                  1.0   \n",
       "\n",
       "       occyp_type_Medicine staff  occyp_type_NAN  \\\n",
       "11221                        0.0             0.0   \n",
       "6693                         0.0             0.0   \n",
       "402                          0.0             1.0   \n",
       "15897                        0.0             1.0   \n",
       "18051                        0.0             1.0   \n",
       "...                          ...             ...   \n",
       "10562                        0.0             0.0   \n",
       "15900                        0.0             0.0   \n",
       "14699                        0.0             0.0   \n",
       "1656                         0.0             0.0   \n",
       "18442                        0.0             0.0   \n",
       "\n",
       "       occyp_type_Private service staff  occyp_type_Realty agents  \\\n",
       "11221                               0.0                       0.0   \n",
       "6693                                0.0                       0.0   \n",
       "402                                 0.0                       0.0   \n",
       "15897                               0.0                       0.0   \n",
       "18051                               0.0                       0.0   \n",
       "...                                 ...                       ...   \n",
       "10562                               0.0                       0.0   \n",
       "15900                               0.0                       0.0   \n",
       "14699                               0.0                       0.0   \n",
       "1656                                0.0                       0.0   \n",
       "18442                               0.0                       0.0   \n",
       "\n",
       "       occyp_type_Sales staff  occyp_type_Secretaries  \\\n",
       "11221                     0.0                     0.0   \n",
       "6693                      0.0                     0.0   \n",
       "402                       0.0                     0.0   \n",
       "15897                     0.0                     0.0   \n",
       "18051                     0.0                     0.0   \n",
       "...                       ...                     ...   \n",
       "10562                     0.0                     0.0   \n",
       "15900                     0.0                     0.0   \n",
       "14699                     0.0                     0.0   \n",
       "1656                      0.0                     0.0   \n",
       "18442                     0.0                     0.0   \n",
       "\n",
       "       occyp_type_Security staff  occyp_type_Waiters/barmen staff  \\\n",
       "11221                        1.0                              0.0   \n",
       "6693                         0.0                              0.0   \n",
       "402                          0.0                              0.0   \n",
       "15897                        0.0                              0.0   \n",
       "18051                        0.0                              0.0   \n",
       "...                          ...                              ...   \n",
       "10562                        0.0                              0.0   \n",
       "15900                        0.0                              0.0   \n",
       "14699                        0.0                              0.0   \n",
       "1656                         0.0                              0.0   \n",
       "18442                        0.0                              0.0   \n",
       "\n",
       "       DAYS_BIRTH_month  DAYS_BIRTH_week  DAYS_EMPLOYED_month  \n",
       "11221               1.0              0.0                  8.0  \n",
       "6693                3.0              0.0                  0.0  \n",
       "402                 9.0              1.0                 -7.0  \n",
       "15897               9.0              1.0                 -7.0  \n",
       "18051               9.0              1.0                 -7.0  \n",
       "...                 ...              ...                  ...  \n",
       "10562               2.0              0.0                 10.0  \n",
       "15900               2.0              0.0                 10.0  \n",
       "14699               2.0              0.0                 10.0  \n",
       "1656                2.0              0.0                 10.0  \n",
       "18442               2.0              0.0                 10.0  \n",
       "\n",
       "[26451 rows x 20 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sort_values(by='income_total').iloc[:, 40:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a2f73ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train.drop(['credit'], axis=1)\n",
    "train_y = train['credit']\n",
    "test_x = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9428cec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "true = train[['credit']]\n",
    "true['0'] = true['credit'][true['credit']==0.0]\n",
    "true['1'] = true['credit'][true['credit']==1.0]\n",
    "true['2'] = true['credit'][true['credit']==2.0]\n",
    "del true['credit']\n",
    "true = true.replace([0.0, 2.0], [1.0, 1.0])\n",
    "true = true.fillna(0)\n",
    "true = true.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ca20b5",
   "metadata": {},
   "source": [
    "# 6. 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0122bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dict = {}\n",
    "pred_test_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e69601",
   "metadata": {},
   "source": [
    "## (1) Lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ea62c2",
   "metadata": {},
   "source": [
    "### Parameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc83a9a5",
   "metadata": {},
   "source": [
    "### 3 seeds x 5 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1de18ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi_logloss : 0.7416561644113113\n",
      "multi_logloss : 0.7442038137777356\n",
      "multi_logloss : 0.7415744730079236\n"
     ]
    }
   ],
   "source": [
    "lucky_seeds=[42,2019,91373]\n",
    "\n",
    "for i, seed in enumerate(lucky_seeds):\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=5, random_state = seed, shuffle = True)\n",
    "    cv=np.zeros((train.shape[0], 3))\n",
    "    #pred_test = np.zeros((test_x.shape[0], 3), dtype=float)\n",
    "    \n",
    "    for n, (train_idx, val_idx) in enumerate(kfold.split(train_x, train_y)):\n",
    "\n",
    "        x_train, x_val = train_x.iloc[train_idx], train_x.iloc[val_idx]\n",
    "        y_train, y_val = train_y.iloc[train_idx], train_y.iloc[val_idx]\n",
    "\n",
    "        lgbmodel = LGBMClassifier(learning_rate=0.01, objective='multiclass', n_estimators=1000,\n",
    "                                   n_jobs=-1, random_state=seed)\n",
    "\n",
    "        lgbmodel.fit(x_train, y_train, eval_set=[(x_val, y_val)], early_stopping_rounds=30, verbose=None) \n",
    "        #joblib.dump(lgbmodel, f'./pred_pkl/LGB_{n+1}_fold_{seed}_seed_lgb.pkl')\n",
    "\n",
    "        # CROSS-VALIDATION , EVALUATE CV\n",
    "        cv[val_idx,:] = lgbmodel.predict_proba(x_val)\n",
    "        #pred_test += lgbmodel.predict_proba(test_x) / 5\n",
    "    #pred_dict['lgb'+str(i+1)] = cv\n",
    "    #pred_test_dict['lgb'+str(i+1)] = pred_test\n",
    "        \n",
    "    print('multi_logloss :', log_loss(true, cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5547d79",
   "metadata": {},
   "source": [
    "# 여기까지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6c11e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7431e179",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3c5ec0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b03420e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750cbf23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc24fc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85d1174",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11b0139",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea8cf140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi_logloss : 0.7015993077380257\n",
      "multi_logloss : 0.7008750060407489\n",
      "multi_logloss : 0.7009575587001414\n"
     ]
    }
   ],
   "source": [
    "lucky_seeds=[42,2019,91373]\n",
    "\n",
    "for i, seed in enumerate(lucky_seeds):\n",
    "\n",
    "    kfold = KFold(n_splits=5, random_state = seed, shuffle = True)\n",
    "    cv=np.zeros((train.shape[0], 3))\n",
    "    #pred_test = np.zeros((test_x.shape[0], 3), dtype=float)\n",
    "    \n",
    "    for n, (train_idx, val_idx) in enumerate(kfold.split(train)):\n",
    "\n",
    "        x_train, x_val = train_x.iloc[train_idx], train_x.iloc[val_idx]\n",
    "        y_train, y_val = train_y.iloc[train_idx], train_y.iloc[val_idx]\n",
    "\n",
    "        lgbmodel = LGBMClassifier(learning_rate=0.005, objective='multiclass', n_estimators=10000, num_leaves=1000, \n",
    "                                  max_depth=-1, min_child_weight=2, colsample_bytree=0.4,  \n",
    "                                   n_jobs=-1, random_state=seed)\n",
    "\n",
    "        lgbmodel.fit(x_train, y_train, eval_set=[(x_val, y_val)], early_stopping_rounds=30, verbose=None) \n",
    "        #joblib.dump(lgbmodel, f'./pred_pkl/LGB_{n+1}_fold_{seed}_seed_lgb.pkl')\n",
    "\n",
    "        # CROSS-VALIDATION , EVALUATE CV\n",
    "        cv[val_idx,:] = lgbmodel.predict_proba(x_val)\n",
    "        #pred_test += lgbmodel.predict_proba(test_x) / 5\n",
    "    #pred_dict['lgb'+str(i+1)] = cv\n",
    "    #pred_test_dict['lgb'+str(i+1)] = pred_test\n",
    "        \n",
    "    print('multi_logloss :', log_loss(true, cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bbf346",
   "metadata": {},
   "outputs": [],
   "source": [
    "lucky_seeds=[42,2019,91373]\n",
    "\n",
    "for i, seed in enumerate(lucky_seeds):\n",
    "\n",
    "    kfold = KFold(n_splits=5, random_state = seed, shuffle = True)\n",
    "    cv=np.zeros((train.shape[0], 3))\n",
    "    #pred_test = np.zeros((test_x.shape[0], 3), dtype=float)\n",
    "    \n",
    "    for n, (train_idx, val_idx) in enumerate(kfold.split(train)):\n",
    "\n",
    "        x_train, x_val = train_x.iloc[train_idx], train_x.iloc[val_idx]\n",
    "        y_train, y_val = train_y.iloc[train_idx], train_y.iloc[val_idx]\n",
    "\n",
    "        lgbmodel = LGBMClassifier(learning_rate=0.005, objective='multiclass', n_estimators=10000, num_leaves=800, \n",
    "                                  max_depth=-1, min_child_weight=2, colsample_bytree=0.4,  \n",
    "                                   n_jobs=-1, random_state=seed)\n",
    "\n",
    "        lgbmodel.fit(x_train, y_train, eval_set=[(x_val, y_val)], early_stopping_rounds=30, verbose=None) \n",
    "        #joblib.dump(lgbmodel, f'./pred_pkl/LGB_{n+1}_fold_{seed}_seed_lgb.pkl')\n",
    "\n",
    "        # CROSS-VALIDATION , EVALUATE CV\n",
    "        cv[val_idx,:] = lgbmodel.predict_proba(x_val)\n",
    "        #pred_test += lgbmodel.predict_proba(test_x) / 5\n",
    "    #pred_dict['lgb'+str(i+1)] = cv\n",
    "    #pred_test_dict['lgb'+str(i+1)] = pred_test\n",
    "        \n",
    "    print('multi_logloss :', log_loss(true, cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a16a9be2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-44585b4fe7fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m                                    n_jobs=-1, random_state=seed)\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mlgbmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;31m#joblib.dump(lgbmodel, f'./pred_pkl/LGB_{n+1}_fold_{seed}_seed_lgb.pkl')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    845\u001b[0m                     \u001b[0mvalid_sets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvalid_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_le\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m         super(LGBMClassifier, self).fit(X, _y, sample_weight=sample_weight,\n\u001b[0m\u001b[1;32m    848\u001b[0m                                         \u001b[0minit_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_sets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m                                         \u001b[0meval_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    610\u001b[0m             \u001b[0minit_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbooster_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m         self._Booster = train(params, train_set,\n\u001b[0m\u001b[1;32m    613\u001b[0m                               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_sets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_sets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m                               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    250\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   2456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__set_objective_to_none\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2457\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot update due to null objective function.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2458\u001b[0;31m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0m\u001b[1;32m   2459\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2460\u001b[0m                 ctypes.byref(is_finished)))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lucky_seeds=[42,2019,91373]\n",
    "\n",
    "for i, seed in enumerate(lucky_seeds):\n",
    "\n",
    "    kfold = KFold(n_splits=5, random_state = seed, shuffle = True)\n",
    "    cv=np.zeros((train.shape[0], 3))\n",
    "    #pred_test = np.zeros((test_x.shape[0], 3), dtype=float)\n",
    "    \n",
    "    for n, (train_idx, val_idx) in enumerate(kfold.split(train)):\n",
    "\n",
    "        x_train, x_val = train_x.iloc[train_idx], train_x.iloc[val_idx]\n",
    "        y_train, y_val = train_y.iloc[train_idx], train_y.iloc[val_idx]\n",
    "\n",
    "        lgbmodel = LGBMClassifier(learning_rate=0.005, objective='multiclass', n_estimators=10000, num_leaves=600, \n",
    "                                  max_depth=-1, min_child_weight=2, colsample_bytree=0.4,  \n",
    "                                   n_jobs=-1, random_state=seed)\n",
    "\n",
    "        lgbmodel.fit(x_train, y_train, eval_set=[(x_val, y_val)], early_stopping_rounds=30, verbose=None) \n",
    "        #joblib.dump(lgbmodel, f'./pred_pkl/LGB_{n+1}_fold_{seed}_seed_lgb.pkl')\n",
    "\n",
    "        # CROSS-VALIDATION , EVALUATE CV\n",
    "        cv[val_idx,:] = lgbmodel.predict_proba(x_val)\n",
    "        #pred_test += lgbmodel.predict_proba(test_x) / 5\n",
    "    #pred_dict['lgb'+str(i+1)] = cv\n",
    "    #pred_test_dict['lgb'+str(i+1)] = pred_test\n",
    "        \n",
    "    print('multi_logloss :', log_loss(true, cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa748213",
   "metadata": {},
   "source": [
    "lgbmodels_path = os.listdir('./pred_pkl/')\n",
    "lgbmodels_list = [x for x in lgbmodels_path if x.endswith(\"lgb.pkl\")]\n",
    "assert len(lgbmodels_list) == 15\n",
    "lgb_preds = np.zeros((test_x.shape[0], 3))\n",
    "\n",
    "for m in lgbmodels_list:\n",
    "    lgbmodel = joblib.load('./pred_pkl/'+m)\n",
    "    lgb_preds_proba = lgbmodel.predict_proba(test)\n",
    "    lgb_preds += lgb_preds_proba/15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f156ef",
   "metadata": {},
   "source": [
    "## (2) XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90efbcab",
   "metadata": {},
   "source": [
    "### Parameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e882c80c",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "params = {'learning_rate':[0.01, 0.005],\n",
    "          'max_depth': [30, 35, 40] # 튜닝할 파라미터 삽입\n",
    "            }\n",
    "\n",
    "xgb_clf = XGBClassifier(n_estimators=100, min_child_weight=2, \n",
    "                        colsample_bytree=0.8, colsample_bylevel=0.8, subsample=0.8,\n",
    "                        num_class=3, objective='multiclass', n_jobs=-1)\n",
    "\n",
    "grid_cv = GridSearchCV(xgb_clf, param_grid=params, cv=5, n_jobs=-1)\n",
    "grid_cv.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6565fc8b",
   "metadata": {},
   "source": [
    "hr_grid_df = pd.DataFrame(grid_cv.cv_results_)\n",
    "hr_grid_df.loc[:, ['mean_test_score', \"params\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db740ef5",
   "metadata": {},
   "source": [
    "### 3 seeds x 5 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d976814b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lucky_seeds=[42, 2019, 91373]\n",
    "xgtest = xgb.DMatrix(test_x)\n",
    "for i, seed in enumerate(lucky_seeds):\n",
    "\n",
    "    kfold = KFold(n_splits=5, random_state = seed, shuffle = True)\n",
    "    cv = np.zeros((train.shape[0], 3))\n",
    "    pred_test = np.zeros((test_x.shape[0], 3), dtype=float)\n",
    "\n",
    "    for n, (train_idx, val_idx) in enumerate(kfold.split(train)):\n",
    "        \n",
    "        x_train, x_val = train_x.iloc[train_idx], train_x.iloc[val_idx]\n",
    "        y_train, y_val = train_y.iloc[train_idx], train_y.iloc[val_idx]\n",
    "        \n",
    "        dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "        dvalid = xgb.DMatrix(x_val, label=y_val)\n",
    "        watchlist = [(dtrain, 'train'), (dvalid, 'valid')]\n",
    "\n",
    "        param = {'objective':'multi:softprob', 'seed':seed, 'num_class': 3, 'eval_metric':'mlogloss', \n",
    "                 'eta': 0.004, 'max_depth': 70, 'min_child_weight': 3,\n",
    "                 'colsample_bytree': 0.3, 'colsample_bylevel': 0.6, 'subsample': 0.8\n",
    "                }\n",
    "\n",
    "        xgbmodel = xgb.train(param, dtrain, 10000, watchlist, early_stopping_rounds=30, verbose_eval=None)\n",
    "        #joblib.dump(xgbmodel, f'./pred_pkl/XGB_{n+1}_fold_{seed}_seed_xgb.pkl')\n",
    "\n",
    "        cv[val_idx, :] = xgbmodel.predict(dvalid)\n",
    "        pred_test += xgbmodel.predict(xgtest) / 5\n",
    "        \n",
    "    pred_dict['xgb'+str(i+1)] = cv\n",
    "    pred_test_dict['xgb'+str(i+1)] = pred_test\n",
    "    print('multi_logloss:', log_loss(true, cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4af31cf",
   "metadata": {},
   "source": [
    "xgbmodels_path = os.listdir('./pred_pkl/')\n",
    "xgbmodels_list = [x for x in xgbmodels_path if x.endswith(\"xgb.pkl\")]\n",
    "assert len(xgbmodels_list) == 15\n",
    "xgb_preds = np.zeros((test_x.shape[0], 3))\n",
    "xgtest = xgb.DMatrix(test_X)\n",
    "\n",
    "for m in xgbmodels_list:\n",
    "    xgbmodel = joblib.load('./pred_pkl/'+m)\n",
    "    xgb_preds_proba = xgbmodel.predict_proba(xgtest)\n",
    "    xgb_preds += xgb_preds_proba/15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae50eed7",
   "metadata": {},
   "source": [
    "## (3) Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb673b7",
   "metadata": {},
   "source": [
    "### GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691af11e",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "params = {'max_depth': [55, 60, 65] # 튜닝할 파라미터 삽입\n",
    "            }\n",
    "\n",
    "rf_clf = RandomForestClassifier(random_state = 0, n_estimators = 1000, \n",
    "                                min_samples_leaf=2, min_samples_split=2,\n",
    "                                criterion='entropy', n_jobs = -1)\n",
    "grid_cv = GridSearchCV(rf_clf, param_grid = params, cv = 5, n_jobs = -1)\n",
    "grid_cv.fit(df_train, y)\n",
    "\n",
    "print('최적 하이퍼 파라미터: ', grid_cv.best_params_)\n",
    "print('최고 예측 정확도: {:.4f}'.format(grid_cv.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9d23e5",
   "metadata": {},
   "source": [
    "### 3 seeds, 5 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae779836",
   "metadata": {},
   "outputs": [],
   "source": [
    "lucky_seeds=[42,2019,91373]\n",
    "for i, seed in enumerate(lucky_seeds):\n",
    "\n",
    "    kfold = KFold(n_splits=5, random_state = seed, shuffle = True)\n",
    "    cv = np.zeros((train.shape[0], 3))\n",
    "    pred_test = np.zeros((test_x.shape[0], 3), dtype=float)\n",
    "    \n",
    "    for n, (train_idx, val_idx) in enumerate(kfold.split(train)):\n",
    "        \n",
    "        x_train, x_val = train_x.iloc[train_idx], train_x.iloc[val_idx]\n",
    "        y_train, y_val = train_y.iloc[train_idx], train_y.iloc[val_idx]\n",
    "\n",
    "        rfmodel = RandomForestClassifier(n_estimators=1000, criterion='entropy', max_depth=55,\n",
    "                                         min_samples_leaf=2, min_samples_split=2,\n",
    "                                         random_state=seed)\n",
    "        rfmodel.fit(x_train, y_train)\n",
    "        #joblib.dump(rfmodel, f'./pred_pkl/RF_{n+1}_fold_{seed}_seed_rf.pkl')\n",
    "        \n",
    "        cv[val_idx, :] = rfmodel.predict_proba(x_val)        \n",
    "        pred_test += rfmodel.predict_proba(test_x) / 5\n",
    "        \n",
    "    pred_dict['rf'+str(i+1)] = cv\n",
    "    pred_test_dict['rf'+str(i+1)] = pred_test\n",
    "    print('multi_logloss :', log_loss(true, cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834d0e02",
   "metadata": {},
   "source": [
    "rfmodels_path = os.listdir('./pred_pkl/')\n",
    "rfmodels_list = [x for x in rfmodels_path if x.endswith(\"rf.pkl\")]\n",
    "assert len(rfmodels_list) == 15\n",
    "rf_preds = np.zeros((test_x.shape[0], 3))\n",
    "\n",
    "for m in rfmodels_list:\n",
    "    rfmodel = joblib.load('./pred_pkl/'+m)\n",
    "    rf_preds_proba = rfmodel.predict_proba(test_x)\n",
    "    rf_preds += rf_preds_proba/15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00b2f34",
   "metadata": {},
   "source": [
    "## (4) Catboost (성능X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91681fa",
   "metadata": {},
   "source": [
    "lucky_seeds=[42,2019,91373]\n",
    "for i, seed in enumerate(lucky_seeds):\n",
    "\n",
    "    kfold = KFold(n_splits=5, random_state = seed, shuffle = True)\n",
    "    cv = np.zeros((train.shape[0], 3))\n",
    "    pred_test = np.zeros((test_x.shape[0], 3), dtype=float)\n",
    "    \n",
    "    for n, (train_idx, val_idx) in enumerate(kfold.split(train)):\n",
    "        \n",
    "        x_train, x_val = train_x.iloc[train_idx], train_x.iloc[val_idx]\n",
    "        y_train, y_val = train_y.iloc[train_idx], train_y.iloc[val_idx]\n",
    "        _train = Pool(x_train, label=y_train)\n",
    "        _valid = Pool(x_val, label=y_val)\n",
    "\n",
    "        catmodel =  CatBoostClassifier(loss_function='MultiClass', early_stopping_rounds=50, \n",
    "                                       random_state=seed, learning_rate=0.02, iterations=100000\n",
    "                                       #task_type=\"GPU\"\n",
    "                                      )\n",
    "        \n",
    "        catmodel.fit(_train, eval_set=_valid, use_best_model=True, verbose=2000)\n",
    "        #joblib.dump(rfmodel, f'./pred_pkl/RF_{n+1}_fold_{seed}_seed_rf.pkl')\n",
    "        \n",
    "        cv[val_idx, :] = catmodel.predict_proba(x_val)        \n",
    "        pred_test += catmodel.predict_proba(test_x) / 5\n",
    "        \n",
    "    pred_dict['cat'+str(i+1)] = cv\n",
    "    pred_test_dict['cat'+str(i+1)] = pred_test\n",
    "    print('multi_logloss :', log_loss(true, cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d716bd37",
   "metadata": {},
   "source": [
    "## (4) Stacking (AutoLGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1df3919",
   "metadata": {},
   "source": [
    "### 27features = 3seed(42, 2019, 91373) x 3model(lgb, xgb, rf) x 3class(0, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7c9d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(np.hstack([x for _, x in pred_dict.items()]))\n",
    "X_test = pd.DataFrame(np.hstack([x for _, x in pred_test_dict.items()]))\n",
    "\n",
    "pred = np.zeros((X_train.shape[0], 3), dtype=float)\n",
    "pred_test = np.zeros((X_test.shape[0], 3), dtype=float)\n",
    "#kfold = KFold(n_splits=5, random_state = seed, shuffle = True)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for i_cv, (i_trn, i_val) in enumerate(cv.split(X_train, train_y)):\n",
    "    if i_cv == 0:\n",
    "        clf = AutoLGB(objective='multiclass', metric='multi_logloss', params={'num_class': 3}, \n",
    "                      feature_selection=False, n_est=10000)\n",
    "        clf.tune(X_train.iloc[i_trn], train_y[i_trn])\n",
    "        n_best = clf.n_best\n",
    "        features = clf.features\n",
    "        params = clf.params\n",
    "        print(f'best iteration: {n_best}')\n",
    "        print(f'selected features ({len(features)}): {features}')        \n",
    "        print(params)\n",
    "        clf.fit(X_train.iloc[i_trn], train_y[i_trn])\n",
    "    else:\n",
    "        train_data = lgb.Dataset(X_train[features].iloc[i_trn], label=train_y[i_trn])\n",
    "        clf = lgb.train(params, train_data, n_best, verbose_eval=100)\n",
    "    \n",
    "    pred[i_val] = clf.predict(X_train[features].iloc[i_val])\n",
    "    pred_test += clf.predict(X_test[features]) / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e6daac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'CV Log Loss: {log_loss(train_y, pred):.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124482db",
   "metadata": {},
   "source": [
    "# 결과 제출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4264cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = sample_submission.copy()\n",
    "submission.iloc[:, 1:] = pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32cfc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission/submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
