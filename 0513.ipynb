{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import glob\n",
    "import os\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "from catboost import Pool, CatBoostClassifier\n",
    "from kaggler.model import AutoLGB\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, GridSearchCV, StratifiedShuffleSplit, train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, log_loss\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 문제 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 데이터 수집"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) 데이콘 기본 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv').drop(['index'], axis=1).fillna('NAN')\n",
    "test = pd.read_csv('data/test.csv').drop(['index'], axis=1).fillna('NAN')\n",
    "sample_submission = pd.read_csv('data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 탐색적 데이터 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 변수 조정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) 이상치 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_data = pd.concat([train, test], axis = 0)\n",
    "\n",
    "# DAYS_BIRTH\n",
    "merge_data['DAYS_BIRTH_month']=np.floor((-merge_data['DAYS_BIRTH'])/30)-(\n",
    "    (np.floor((-merge_data['DAYS_BIRTH'])/30)/12).astype(int)*12)\n",
    "merge_data['DAYS_BIRTH_week']=np.floor((-merge_data['DAYS_BIRTH'])/7)-(\n",
    "    (np.floor((-merge_data['DAYS_BIRTH'])/7)/4).astype(int)*4)\n",
    "\n",
    "# DAYS_EMPLOYED\n",
    "merge_data['DAYS_EMPLOYED_month']=np.floor((-merge_data['DAYS_EMPLOYED'])/30)-(\n",
    "    (np.floor((-merge_data['DAYS_EMPLOYED'])/30)/12).astype(int)*12)\n",
    "merge_data['DAYS_EMPLOYED_week']=np.floor((-merge_data['DAYS_EMPLOYED'])/7)-(\n",
    "    (np.floor((-merge_data['DAYS_EMPLOYED'])/7)/4).astype(int)*4)\n",
    "\n",
    "# before_EMPLOYED\n",
    "merge_data['before_EMPLOYED']=merge_data['DAYS_BIRTH']-merge_data['DAYS_EMPLOYED']\n",
    "merge_data['before_EMPLOYED_month']=np.floor((-merge_data['before_EMPLOYED'])/30)-(\n",
    "    (np.floor((-merge_data['before_EMPLOYED'])/30)/12).astype(int)*12)\n",
    "merge_data['before_EMPLOYED_week']=np.floor((-merge_data['before_EMPLOYED'])/7)-(\n",
    "    (np.floor((-merge_data['before_EMPLOYED'])/7)/4).astype(int)*4)\n",
    "\n",
    "# DAYS_BIRTH\n",
    "merge_data['1new_1'] = merge_data['DAYS_BIRTH_month'] / merge_data['income_total']\n",
    "merge_data['2new_1'] = merge_data['DAYS_BIRTH_week'] / merge_data['income_total']\n",
    "\n",
    "# DAYS_EMPLOYED\n",
    "merge_data['10new_1'] = merge_data['DAYS_EMPLOYED_month'] / merge_data['income_total']\n",
    "merge_data['11new_1'] = merge_data['DAYS_EMPLOYED_week'] / merge_data['income_total']\n",
    "\n",
    "# before_EMPLOYED\n",
    "merge_data['12new_1'] = merge_data['before_EMPLOYED'] / merge_data['income_total']\n",
    "merge_data['13new_1'] = merge_data['before_EMPLOYED_month'] / merge_data['income_total']\n",
    "merge_data['14new_1'] = merge_data['before_EMPLOYED_week'] / merge_data['income_total']\n",
    "\n",
    "# 융합 삭제\n",
    "#merge_data['3new_1'] = merge_data['DAYS_EMPLOYED_month'] / merge_data['DAYS_BIRTH_month']\n",
    "#merge_data['4new_1'] = merge_data['DAYS_EMPLOYED_month'] / merge_data['DAYS_BIRTH_week']\n",
    "#merge_data['5new_1'] = merge_data['DAYS_EMPLOYED_week'] / merge_data['DAYS_BIRTH_month']\n",
    "#merge_data['6new_1'] = merge_data['DAYS_EMPLOYED_week'] / merge_data['DAYS_BIRTH_week']\n",
    "\n",
    "#merge_data['7new_1'] =  merge_data['begin_month'] / merge_data['DAYS_BIRTH_month']\n",
    "#merge_data['8new_1'] =  merge_data['begin_month'] / merge_data['DAYS_EMPLOYED_month']\n",
    "#merge_data['9new_1'] =  merge_data['begin_month'] / merge_data['before_EMPLOYED_month']\n",
    "\n",
    "\n",
    "# 소득대비 \n",
    "merge_data['DAYS_BIRTH'] = merge_data['DAYS_BIRTH'] / -365\n",
    "merge_data['DAYS_EMPLOYED'] = merge_data['DAYS_EMPLOYED'] / -365\n",
    "\n",
    "merge_data['new_1'] = merge_data['child_num'] / merge_data['income_total']\n",
    "merge_data['new_2'] = merge_data['family_size'] / merge_data['income_total']\n",
    "merge_data['new_3'] = merge_data['DAYS_BIRTH'] / merge_data['income_total']\n",
    "merge_data['new_4'] = merge_data['DAYS_EMPLOYED'] / merge_data['income_total']\n",
    "merge_data['new_5'] = merge_data['begin_month'] / merge_data['income_total']\n",
    "merge_data['new_6'] =  merge_data['DAYS_EMPLOYED'] / merge_data['DAYS_BIRTH']\n",
    "\n",
    "# 소득 skewed-data 처리\n",
    "# merge_data['log_income_total'] = np.log(merge_data['income_total'])\n",
    "# merge_data['sqrt_income_total'] = np.sqrt(merge_data['income_total'])\n",
    "# merge_data['boxcox_income_total'] = stats.boxcox(merge_data['income_total'])[0]\n",
    "\n",
    "merge_data = merge_data.fillna(-999)\n",
    "train = merge_data[merge_data['credit'] != -999]\n",
    "test = merge_data[merge_data['credit'] == -999]\n",
    "test.drop('credit', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "train = train[train['child_num']<=6].reset_index(drop=True) # 아이의 수가 7명 이상인 데이터 제거"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_oh = train.copy()\n",
    "train_noh = train.copy()\n",
    "test_oh = test.copy()\n",
    "test_noh = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_col = []\n",
    "for col in train_noh.columns:\n",
    "    if train_noh[col].dtype == 'object':\n",
    "        train_noh[col] = train_noh[col].astype('category')\n",
    "        test_noh[col] = test_noh[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gender', 'car', 'reality', 'income_type', 'edu_type', 'family_type', 'house_type', 'occyp_type']\n"
     ]
    }
   ],
   "source": [
    "object_col = []\n",
    "for col in train_oh.columns:\n",
    "    if train_oh[col].dtype == 'object':\n",
    "        object_col.append(col)\n",
    "print(object_col)        \n",
    "enc = OneHotEncoder()\n",
    "enc.fit(train.loc[:,object_col])\n",
    "\n",
    "\n",
    "train_onehot_df = pd.DataFrame(enc.transform(train_oh.loc[:,object_col]).toarray(), \n",
    "             columns=enc.get_feature_names(object_col))\n",
    "train_oh.drop(object_col, axis=1, inplace=True)\n",
    "train_oh = pd.concat([train_oh, train_onehot_df], axis=1)    \n",
    "\n",
    "test_onehot_df = pd.DataFrame(enc.transform(test_oh.loc[:,object_col]).toarray(), \n",
    "             columns=enc.get_feature_names(object_col))\n",
    "test_oh.drop(object_col, axis=1, inplace=True)\n",
    "test_oh = pd.concat([test_oh, test_onehot_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "true = train[['credit']]\n",
    "true['0'] = true['credit'][true['credit']==0.0]\n",
    "true['1'] = true['credit'][true['credit']==1.0]\n",
    "true['2'] = true['credit'][true['credit']==2.0]\n",
    "del true['credit']\n",
    "true = true.replace([0.0, 2.0], [1.0, 1.0])\n",
    "true = true.fillna(0)\n",
    "true = true.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dict = {}\n",
    "pred_test_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_noh.drop(['credit'], axis=1)\n",
    "train_y = train_noh['credit']\n",
    "test_x = test_noh.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 seeds x 5 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi_logloss : 0.6915101725662152\n",
      "multi_logloss : 0.6915843058850291\n",
      "multi_logloss : 0.6912776413331292\n"
     ]
    }
   ],
   "source": [
    "lucky_seeds=[42,2019,91373]\n",
    "for i, seed in enumerate(lucky_seeds):\n",
    "\n",
    "    kfold = KFold(n_splits=10, random_state = seed, shuffle = True)\n",
    "    cv=np.zeros((train.shape[0], 3))\n",
    "    pred_test = np.zeros((test_x.shape[0], 3), dtype=float)\n",
    "    \n",
    "    for n, (train_idx, val_idx) in enumerate(kfold.split(train)):\n",
    "\n",
    "        x_train, x_val = train_x.iloc[train_idx], train_x.iloc[val_idx]\n",
    "        y_train, y_val = train_y.iloc[train_idx], train_y.iloc[val_idx]\n",
    "\n",
    "        lgbmodel = LGBMClassifier(learning_rate=0.005, objective='multiclass', n_estimators=10000, num_leaves=1000, \n",
    "                                  max_depth=-1, min_child_weight=2, colsample_bytree=0.4,  \n",
    "                                   n_jobs=-1, random_state=seed)\n",
    "\n",
    "        lgbmodel.fit(x_train, y_train, eval_set=[(x_val, y_val)], early_stopping_rounds=30, verbose=None) \n",
    "        #joblib.dump(lgbmodel, f'./pred_pkl/LGB_{n+1}_fold_{seed}_seed_lgb.pkl')\n",
    "\n",
    "        # CROSS-VALIDATION , EVALUATE CV\n",
    "        cv[val_idx,:] = lgbmodel.predict_proba(x_val)\n",
    "        pred_test += lgbmodel.predict_proba(test_x) / 10\n",
    "    pred_dict['lgb'+str(i+1)] = cv\n",
    "    pred_test_dict['lgb'+str(i+1)] = pred_test\n",
    "        \n",
    "    print('multi_logloss :', log_loss(true, cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lgbmodels_path = os.listdir('./pred_pkl/')\n",
    "lgbmodels_list = [x for x in lgbmodels_path if x.endswith(\"lgb.pkl\")]\n",
    "assert len(lgbmodels_list) == 15\n",
    "lgb_preds = np.zeros((test_x.shape[0], 3))\n",
    "\n",
    "for m in lgbmodels_list:\n",
    "    lgbmodel = joblib.load('./pred_pkl/'+m)\n",
    "    lgb_preds_proba = lgbmodel.predict_proba(test)\n",
    "    lgb_preds += lgb_preds_proba/15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_oh.drop(['credit'], axis=1)\n",
    "train_y = train_oh['credit']\n",
    "test_x = test_oh.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_x, train_y, test_size=0.2, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = pd.DataFrame(y_test, columns=['credit'])\n",
    "y_test['0'] = y_test['credit'][y_test['credit']==0.0]\n",
    "y_test['1'] = y_test['credit'][y_test['credit']==1.0]\n",
    "y_test['2'] = y_test['credit'][y_test['credit']==2.0]\n",
    "del y_test['credit']\n",
    "y_test = y_test.replace([0.0, 2.0], [1.0, 1.0])\n",
    "y_test = y_test.fillna(0)\n",
    "y_test = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.DataFrame(y_train, columns=['credit'])\n",
    "y_train['0'] = y_train['credit'][y_train['credit']==0.0]\n",
    "y_train['1'] = y_train['credit'][y_train['credit']==1.0]\n",
    "y_train['2'] = y_train['credit'][y_train['credit']==2.0]\n",
    "del y_train['credit']\n",
    "y_train = y_train.replace([0.0, 2.0], [1.0, 1.0])\n",
    "y_train = y_train.fillna(0)\n",
    "y_train = y_train.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "true = train[['credit']]\n",
    "true['0'] = true['credit'][true['credit']==0.0]\n",
    "true['1'] = true['credit'][true['credit']==1.0]\n",
    "true['2'] = true['credit'][true['credit']==2.0]\n",
    "del true['credit']\n",
    "true = true.replace([0.0, 2.0], [1.0, 1.0])\n",
    "true = true.fillna(0)\n",
    "true = true.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials, space_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "space={'max_depth': hp.quniform(\"max_depth\", 3, 18, 1),\n",
    "        'gamma': hp.uniform ('gamma', 1,9),\n",
    "        'reg_alpha' : hp.quniform('reg_alpha', 40,180,1),\n",
    "        'reg_lambda' : hp.uniform('reg_lambda', 0,1),\n",
    "        'colsample_bytree' : hp.uniform('colsample_bytree', 0.5,1),\n",
    "        'min_child_weight' : hp.quniform('min_child_weight', 0, 10, 1),\n",
    "        'n_estimators': 300,\n",
    "        'seed': 0\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(space):\n",
    "    clf=xgb.XGBClassifier(\n",
    "                    n_estimators =space['n_estimators'], max_depth = int(space['max_depth']), gamma = space['gamma'],\n",
    "                    reg_alpha = int(space['reg_alpha']),min_child_weight=int(space['min_child_weight']),\n",
    "                    colsample_bytree=int(space['colsample_bytree']), objective = 'multi:softprob', eval_metric='mlogloss')\n",
    "    \n",
    "    evaluation = [(X_train, y_train), (X_test, y_test)]\n",
    "    \n",
    "    clf.fit(X_train, y_train, \n",
    "            eval_set=evaluation, eval_metric=\"mlogloss\",\n",
    "            early_stopping_rounds=30,verbose=False)\n",
    "    \n",
    "\n",
    "    pred = clf.predict(X_test)\n",
    "    logloss = log_loss(true, pred)\n",
    "    print (\"SCORE:\", logloss)\n",
    "    return {'loss': logloss, 'status': STATUS_OK }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                          | 0/100 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: y should be a 1d array, got an array of shape (2400, 20) instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                                          | 0/100 [00:00<?, ?trial/s, best loss=?]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y should be a 1d array, got an array of shape (2400, 20) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-133-e948e57d088a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtrials\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrials\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m best_hyperparams = fmin(fn = objective,\n\u001b[0m\u001b[0;32m      4\u001b[0m                         \u001b[0mspace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                         \u001b[0malgo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtpe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    505\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mallow_trials_fmin\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"fmin\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 507\u001b[1;33m         return trials.fmin(\n\u001b[0m\u001b[0;32m    508\u001b[0m             \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m             \u001b[0mspace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\hyperopt\\base.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    680\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mfmin\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfmin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    681\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 682\u001b[1;33m         return fmin(\n\u001b[0m\u001b[0;32m    683\u001b[0m             \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    684\u001b[0m             \u001b[0mspace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    551\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m     \u001b[1;31m# next line is where the fmin is actually executed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 553\u001b[1;33m     \u001b[0mrval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    354\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 356\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    357\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, N, block_until_done)\u001b[0m\n\u001b[0;32m    290\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m                     \u001b[1;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[1;34m(self, N)\u001b[0m\n\u001b[0;32m    168\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    171\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"job exception: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\hyperopt\\base.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[0;32m    905\u001b[0m                 \u001b[0mprint_node_on_error\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrec_eval_print_node_on_error\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    906\u001b[0m             )\n\u001b[1;32m--> 907\u001b[1;33m             \u001b[0mrval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    908\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-132-b4b743d4d48d>\u001b[0m in \u001b[0;36mobjective\u001b[1;34m(space)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mevaluation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     clf.fit(X_train, y_train, \n\u001b[0m\u001b[0;32m     11\u001b[0m             \u001b[0meval_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevaluation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             early_stopping_rounds=30,verbose=False)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\multioutput.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, Y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    349\u001b[0m         \u001b[0mself\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m         \"\"\"\n\u001b[1;32m--> 351\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    352\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mestimator\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\multioutput.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[0mfit_params_validated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_fit_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 172\u001b[1;33m         self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n\u001b[0m\u001b[0;32m    173\u001b[0m             delayed(_fit_estimator)(\n\u001b[0;32m    174\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1046\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1047\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1048\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1049\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    864\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 866\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    867\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    782\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    783\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 784\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    785\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\multioutput.py\u001b[0m in \u001b[0;36m_fit_estimator\u001b[1;34m(estimator, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    431\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1156\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Please reshape the input data X into 2-dimensional matrix.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1158\u001b[1;33m         train_dmatrix, evals = _wrap_evaluation_matrices(\n\u001b[0m\u001b[0;32m   1159\u001b[0m             \u001b[0mmissing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1160\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36m_wrap_evaluation_matrices\u001b[1;34m(missing, X, y, group, qid, sample_weight, base_margin, feature_weights, eval_set, sample_weight_eval_set, base_margin_eval_set, eval_group, eval_qid, create_dmatrix, label_transform)\u001b[0m\n\u001b[0;32m    281\u001b[0m                 m = create_dmatrix(\n\u001b[0;32m    282\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalid_X\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 283\u001b[1;33m                     \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabel_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    284\u001b[0m                     \u001b[0mweight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight_eval_set\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m                     \u001b[0mgroup\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_group\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    270\u001b[0m         \"\"\"\n\u001b[0;32m    271\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 272\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    273\u001b[0m         \u001b[1;31m# transform of empty array is empty array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[1;34m(y, warn)\u001b[0m\n\u001b[0;32m    843\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    844\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 845\u001b[1;33m     raise ValueError(\n\u001b[0m\u001b[0;32m    846\u001b[0m         \u001b[1;34m\"y should be a 1d array, \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    847\u001b[0m         \"got an array of shape {} instead.\".format(shape))\n",
      "\u001b[1;31mValueError\u001b[0m: y should be a 1d array, got an array of shape (2400, 20) instead."
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "\n",
    "best_hyperparams = fmin(fn = objective,\n",
    "                        space = space,\n",
    "                        algo = tpe.suggest,\n",
    "                        max_evals = 100,\n",
    "                        trials = trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    5.9s remaining:   21.0s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   9 | elapsed:    5.9s remaining:   12.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   9 | elapsed: 26.4min remaining: 33.0min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   9 | elapsed: 32.3min remaining: 25.8min\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed: 33.0min remaining: 16.5min\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of   9 | elapsed: 39.0min remaining: 11.1min\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed: 44.4min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed: 44.4min finished\n",
      "[10:03:31] DEBUG: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/tree/updater_gpu_hist.cu:899: [GPU Hist]: Configure\n",
      "[10:03:31] ======== Monitor: SketchContainer ========\n",
      "[10:03:31] MakeCuts: 0.001705s, 1 calls @ 1705us\n",
      "\n",
      "[10:03:31] Prune: 0.000932s, 1 calls @ 932us\n",
      "\n",
      "[10:03:31] ScanInput: 0.001104s, 1 calls @ 1104us\n",
      "\n",
      "[10:03:31] Unique: 0.000557s, 1 calls @ 557us\n",
      "\n",
      "[10:03:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[10:11:13] ======== Monitor: Learner ========\n",
      "[10:11:13] Configure: 0.003938s, 1 calls @ 3938us\n",
      "\n",
      "[10:11:13] EvalOneIter: 0.002027s, 100 calls @ 2027us\n",
      "\n",
      "[10:11:13] GetGradient: 0.0091s, 100 calls @ 9100us\n",
      "\n",
      "[10:11:13] PredictRaw: 0.223043s, 100 calls @ 223043us\n",
      "\n",
      "[10:11:13] UpdateOneIter: 457.245s, 100 calls @ 457245108us\n",
      "\n",
      "[10:11:13] ======== Monitor: GBTree ========\n",
      "[10:11:13] BoostNewTrees: 457.005s, 100 calls @ 457005257us\n",
      "\n",
      "[10:11:13] CommitModel: 0.00014s, 100 calls @ 140us\n",
      "\n",
      "[10:11:13] ======== Device 0 Memory Allocations:  ========\n",
      "[10:11:13] Peak memory usage: 377MiB\n",
      "[10:11:13] Number of allocations: 4524583\n",
      "[10:11:13] ======== Monitor: updater_gpu_hist ========\n",
      "[10:11:13] InitData: 2.88471s, 300 calls @ 2884714us\n",
      "\n",
      "[10:11:13] InitDataOnce: 2.88466s, 1 calls @ 2884658us\n",
      "\n",
      "[10:11:13] Update: 456.876s, 300 calls @ 456875881us\n",
      "\n",
      "[10:11:13] ======== Monitor: gradient_based_sampler ========\n",
      "[10:11:13] Sample: 0.032102s, 300 calls @ 32102us\n",
      "\n",
      "[10:11:13] ======== Monitor: GPUHistMakerDevice0 ========\n",
      "[10:11:13] AllReduce: 0.088616s, 464498 calls @ 88616us\n",
      "\n",
      "[10:11:13] BuildHist: 4.36747s, 464198 calls @ 4367466us\n",
      "\n",
      "[10:11:13] EvaluateSplits: 8.21575s, 464198 calls @ 8215747us\n",
      "\n",
      "[10:11:13] FinalisePosition: 0.021678s, 300 calls @ 21678us\n",
      "\n",
      "[10:11:13] InitRoot: 0.643591s, 300 calls @ 643591us\n",
      "\n",
      "[10:11:13] Reset: 360.443s, 300 calls @ 360443313us\n",
      "\n",
      "[10:11:13] UpdatePosition: 78.2491s, 464198 calls @ 78249120us\n",
      "\n",
      "[10:11:13] ======== Monitor: ellpack_page ========\n",
      "[10:11:13] BinningCompression: 0.004642s, 1 calls @ 4642us\n",
      "\n",
      "[10:11:13] InitCompressedData: 0.000472s, 1 calls @ 472us\n",
      "\n",
      "[10:11:13] Quantiles: 0.024513s, 1 calls @ 24513us\n",
      "\n",
      "Wall time: 52min 6s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=0.8,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=0.8, gamma=None,\n",
       "                                     gpu_id=None, importance_type='gain',\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weight=2,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=-1, num_class=3,\n",
       "                                     num_parallel_tree=None,\n",
       "                                     objective='multiclass', random_state=None,\n",
       "                                     reg_alpha=None, reg_lambda=None,\n",
       "                                     scale_pos_weight=None, subsample=0.8,\n",
       "                                     tree_method='gpu_hist',\n",
       "                                     validate_parameters=None, verbosity=None),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.02, 0.01, 0.006],\n",
       "                         'max_depth': [30]},\n",
       "             verbose=300)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "params = {'learning_rate':[0.02, 0.01, 0.006],\n",
    "          'max_depth': [30] # 튜닝할 파라미터 삽입\n",
    "            }\n",
    "xgb_clf = XGBClassifier(n_estimators=100, min_child_weight=2, \n",
    "                        colsample_bytree=0.8, colsample_bylevel=0.8, subsample=0.8, tree_method='gpu_hist',\n",
    "                        num_class=3, objective='multiclass', n_jobs=-1)\n",
    "\n",
    "grid_cv = GridSearchCV(xgb_clf, param_grid=params, cv=3, n_jobs=-1, verbose=300)\n",
    "grid_cv.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.715538</td>\n",
       "      <td>{'learning_rate': 0.02, 'max_depth': 30}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.716824</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 30}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>{'learning_rate': 0.006, 'max_depth': 30}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_test_score                                     params\n",
       "0         0.715538   {'learning_rate': 0.02, 'max_depth': 30}\n",
       "1         0.716824   {'learning_rate': 0.01, 'max_depth': 30}\n",
       "2              NaN  {'learning_rate': 0.006, 'max_depth': 30}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr_grid_df = pd.DataFrame(grid_cv.cv_results_)\n",
    "hr_grid_df.loc[:, ['mean_test_score', \"params\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:  8.4min\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of  12 | elapsed:  8.4min remaining: 42.0min\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  12 | elapsed:  8.5min remaining: 25.4min\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of  12 | elapsed:  8.7min remaining: 17.5min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  12 | elapsed:  8.8min remaining: 12.3min\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  12 | elapsed:  8.8min remaining:  8.8min\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  12 | elapsed: 10.0min remaining:  7.1min\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  12 | elapsed: 10.0min remaining:  5.0min\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of  12 | elapsed: 10.0min remaining:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  12 | elapsed: 10.1min remaining:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed: 10.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed: 10.2min finished\n",
      "[09:14:57] DEBUG: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/tree/updater_gpu_hist.cu:899: [GPU Hist]: Configure\n",
      "[09:14:57] ======== Monitor: SketchContainer ========\n",
      "[09:14:57] MakeCuts: 0.001582s, 1 calls @ 1582us\n",
      "\n",
      "[09:14:57] Prune: 0.000937s, 1 calls @ 937us\n",
      "\n",
      "[09:14:57] ScanInput: 0.000853s, 1 calls @ 853us\n",
      "\n",
      "[09:14:57] Unique: 0.00057s, 1 calls @ 570us\n",
      "\n",
      "[09:14:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:16:00] ======== Monitor: Learner ========\n",
      "[09:16:00] Configure: 0.000914s, 1 calls @ 914us\n",
      "\n",
      "[09:16:00] EvalOneIter: 0.001043s, 100 calls @ 1043us\n",
      "\n",
      "[09:16:00] GetGradient: 0.007837s, 100 calls @ 7837us\n",
      "\n",
      "[09:16:00] PredictRaw: 0.175531s, 100 calls @ 175531us\n",
      "\n",
      "[09:16:00] UpdateOneIter: 59.3822s, 100 calls @ 59382235us\n",
      "\n",
      "[09:16:00] ======== Monitor: GBTree ========\n",
      "[09:16:00] BoostNewTrees: 59.1958s, 100 calls @ 59195806us\n",
      "\n",
      "[09:16:00] CommitModel: 6.2e-05s, 100 calls @ 62us\n",
      "\n",
      "[09:16:00] ======== Device 0 Memory Allocations:  ========\n",
      "[09:16:00] Peak memory usage: 377MiB\n",
      "[09:16:00] Number of allocations: 2188605\n",
      "[09:16:00] ======== Monitor: updater_gpu_hist ========\n",
      "[09:16:00] InitData: 0.024002s, 300 calls @ 24002us\n",
      "\n",
      "[09:16:00] InitDataOnce: 0.023956s, 1 calls @ 23956us\n",
      "\n",
      "[09:16:00] Update: 59.1008s, 300 calls @ 59100804us\n",
      "\n",
      "[09:16:00] ======== Monitor: gradient_based_sampler ========\n",
      "[09:16:00] Sample: 0.016215s, 300 calls @ 16215us\n",
      "\n",
      "[09:16:00] ======== Monitor: GPUHistMakerDevice0 ========\n",
      "[09:16:00] AllReduce: 0.06441s, 267472 calls @ 64410us\n",
      "\n",
      "[09:16:00] BuildHist: 3.10114s, 267172 calls @ 3101145us\n",
      "\n",
      "[09:16:00] EvaluateSplits: 6.31328s, 267172 calls @ 6313282us\n",
      "\n",
      "[09:16:00] FinalisePosition: 0.022651s, 300 calls @ 22651us\n",
      "\n",
      "[09:16:00] InitRoot: 0.569734s, 300 calls @ 569734us\n",
      "\n",
      "[09:16:00] Reset: 0.367396s, 300 calls @ 367396us\n",
      "\n",
      "[09:16:00] UpdatePosition: 47.4946s, 267172 calls @ 47494591us\n",
      "\n",
      "[09:16:00] ======== Monitor: ellpack_page ========\n",
      "[09:16:00] BinningCompression: 0.004696s, 1 calls @ 4696us\n",
      "\n",
      "[09:16:00] InitCompressedData: 0.000498s, 1 calls @ 498us\n",
      "\n",
      "[09:16:00] Quantiles: 0.017643s, 1 calls @ 17643us\n",
      "\n",
      "Wall time: 11min 12s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=0.8,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=0.8, gamma=None,\n",
       "                                     gpu_id=None, importance_type='gain',\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weight=2,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=-1, num_class=3,\n",
       "                                     num_parallel_tree=None,\n",
       "                                     objective='multiclass', random_state=None,\n",
       "                                     reg_alpha=None, reg_lambda=None,\n",
       "                                     scale_pos_weight=None, subsample=0.8,\n",
       "                                     tree_method='gpu_hist',\n",
       "                                     validate_parameters=None, verbosity=None),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.03, 0.01], 'max_depth': [18, 23]},\n",
       "             verbose=300)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "params = {'learning_rate':[0.03, 0.01],\n",
    "          'max_depth': [18, 23] # 튜닝할 파라미터 삽입\n",
    "            }\n",
    "xgb_clf = XGBClassifier(n_estimators=100, min_child_weight=2, \n",
    "                        colsample_bytree=0.8, colsample_bylevel=0.8, subsample=0.8, tree_method='gpu_hist',\n",
    "                        num_class=3, objective='multiclass', n_jobs=-1)\n",
    "\n",
    "grid_cv = GridSearchCV(xgb_clf, param_grid=params, cv=3, n_jobs=-1, verbose=300)\n",
    "grid_cv.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.716370</td>\n",
       "      <td>{'learning_rate': 0.03, 'max_depth': 18}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.714669</td>\n",
       "      <td>{'learning_rate': 0.03, 'max_depth': 23}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.714178</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 18}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.715463</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 23}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_test_score                                    params\n",
       "0         0.716370  {'learning_rate': 0.03, 'max_depth': 18}\n",
       "1         0.714669  {'learning_rate': 0.03, 'max_depth': 23}\n",
       "2         0.714178  {'learning_rate': 0.01, 'max_depth': 18}\n",
       "3         0.715463  {'learning_rate': 0.01, 'max_depth': 23}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr_grid_df = pd.DataFrame(grid_cv.cv_results_)\n",
    "hr_grid_df.loc[:, ['mean_test_score', \"params\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 seeds x 5 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:1.09405\tvalid-mlogloss:1.09414\n",
      "[100]\ttrain-mlogloss:0.87494\tvalid-mlogloss:0.88147\n",
      "[200]\ttrain-mlogloss:0.80393\tvalid-mlogloss:0.81991\n",
      "[300]\ttrain-mlogloss:0.77248\tvalid-mlogloss:0.79792\n",
      "[400]\ttrain-mlogloss:0.75215\tvalid-mlogloss:0.78653\n",
      "[500]\ttrain-mlogloss:0.73599\tvalid-mlogloss:0.77848\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-b2607ddb2ae4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m                 }\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mxgbmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwatchlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[1;31m#joblib.dump(xgbmodel, f'./pred_pkl/XGB_{n+1}_fold_{seed}_seed_xgb.pkl')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[0mBooster\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mbooster\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m     \"\"\"\n\u001b[1;32m--> 189\u001b[1;33m     bst = _train_internal(params, dtrain,\n\u001b[0m\u001b[0;32m    190\u001b[0m                           \u001b[0mnum_boost_round\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m                           \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m         \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1494\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1495\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1496\u001b[1;33m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0m\u001b[0;32m   1497\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1498\u001b[0m                                                     dtrain.handle))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lucky_seeds=[42, 2019, 91373]\n",
    "xgtest = xgb.DMatrix(test_x)\n",
    "for i, seed in enumerate(lucky_seeds):\n",
    "\n",
    "    kfold = KFold(n_splits=10, random_state = seed, shuffle = True)\n",
    "    cv = np.zeros((train.shape[0], 3))\n",
    "    pred_test = np.zeros((test_x.shape[0], 3), dtype=float)\n",
    "\n",
    "    for n, (train_idx, val_idx) in enumerate(kfold.split(train)):\n",
    "        \n",
    "        x_train, x_val = train_x.iloc[train_idx], train_x.iloc[val_idx]\n",
    "        y_train, y_val = train_y.iloc[train_idx], train_y.iloc[val_idx]\n",
    "        \n",
    "        dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "        dvalid = xgb.DMatrix(x_val, label=y_val)\n",
    "        watchlist = [(dtrain, 'train'), (dvalid, 'valid')]\n",
    "\n",
    "        param = {'objective':'multi:softprob', 'seed':seed, 'num_class': 3, 'eval_metric':'mlogloss', \n",
    "                 'eta': 0.01, 'min_child_weight': 3, 'tree_method':'gpu_hist',\n",
    "                 'colsample_bytree': 0.3, 'colsample_bylevel': 0.6, 'subsample': 0.8\n",
    "                }\n",
    "\n",
    "        xgbmodel = xgb.train(param, dtrain, 100000, watchlist, early_stopping_rounds=30, verbose_eval=100)\n",
    "        #joblib.dump(xgbmodel, f'./pred_pkl/XGB_{n+1}_fold_{seed}_seed_xgb.pkl')\n",
    "\n",
    "        cv[val_idx, :] = xgbmodel.predict(dvalid)\n",
    "        pred_test += xgbmodel.predict(xgtest) / 10\n",
    "        \n",
    "    pred_dict['xgb'+str(i+1)] = cv\n",
    "    pred_test_dict['xgb'+str(i+1)] = pred_test\n",
    "    print('multi_logloss:', log_loss(true, cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xgbmodels_path = os.listdir('./pred_pkl/')\n",
    "xgbmodels_list = [x for x in xgbmodels_path if x.endswith(\"xgb.pkl\")]\n",
    "assert len(xgbmodels_list) == 15\n",
    "xgb_preds = np.zeros((test_x.shape[0], 3))\n",
    "xgtest = xgb.DMatrix(test_X)\n",
    "\n",
    "for m in xgbmodels_list:\n",
    "    xgbmodel = joblib.load('./pred_pkl/'+m)\n",
    "    xgb_preds_proba = xgbmodel.predict_proba(xgtest)\n",
    "    xgb_preds += xgb_preds_proba/15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "params = {'max_depth': [55, 60, 65] # 튜닝할 파라미터 삽입\n",
    "            }\n",
    "\n",
    "rf_clf = RandomForestClassifier(random_state = 0, n_estimators = 1000, \n",
    "                                min_samples_leaf=2, min_samples_split=2,\n",
    "                                criterion='entropy', n_jobs = -1)\n",
    "grid_cv = GridSearchCV(rf_clf, param_grid = params, cv = 5, n_jobs = -1)\n",
    "grid_cv.fit(df_train, y)\n",
    "\n",
    "print('최적 하이퍼 파라미터: ', grid_cv.best_params_)\n",
    "print('최고 예측 정확도: {:.4f}'.format(grid_cv.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 seeds, 5 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lucky_seeds=[42,2019,91373]\n",
    "for i, seed in enumerate(lucky_seeds):\n",
    "\n",
    "    kfold = KFold(n_splits=10, random_state = seed, shuffle = True)\n",
    "    cv = np.zeros((train.shape[0], 3))\n",
    "    pred_test = np.zeros((test_x.shape[0], 3), dtype=float)\n",
    "    \n",
    "    for n, (train_idx, val_idx) in enumerate(kfold.split(train)):\n",
    "        \n",
    "        x_train, x_val = train_x.iloc[train_idx], train_x.iloc[val_idx]\n",
    "        y_train, y_val = train_y.iloc[train_idx], train_y.iloc[val_idx]\n",
    "\n",
    "        rfmodel = RandomForestClassifier(n_estimators=1000, criterion='entropy', max_depth=55,\n",
    "                                         min_samples_leaf=2, min_samples_split=2,\n",
    "                                         random_state=seed)\n",
    "        rfmodel.fit(x_train, y_train)\n",
    "        #joblib.dump(rfmodel, f'./pred_pkl/RF_{n+1}_fold_{seed}_seed_rf.pkl')\n",
    "        \n",
    "        cv[val_idx, :] = rfmodel.predict_proba(x_val)        \n",
    "        pred_test += rfmodel.predict_proba(test_x) / 10\n",
    "        \n",
    "    pred_dict['rf'+str(i+1)] = cv\n",
    "    pred_test_dict['rf'+str(i+1)] = pred_test\n",
    "    print('multi_logloss :', log_loss(true, cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rfmodels_path = os.listdir('./pred_pkl/')\n",
    "rfmodels_list = [x for x in rfmodels_path if x.endswith(\"rf.pkl\")]\n",
    "assert len(rfmodels_list) == 15\n",
    "rf_preds = np.zeros((test_x.shape[0], 3))\n",
    "\n",
    "for m in rfmodels_list:\n",
    "    rfmodel = joblib.load('./pred_pkl/'+m)\n",
    "    rf_preds_proba = rfmodel.predict_proba(test_x)\n",
    "    rf_preds += rf_preds_proba/15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) Catboost (성능X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lucky_seeds=[42,2019,91373]\n",
    "for i, seed in enumerate(lucky_seeds):\n",
    "\n",
    "    kfold = KFold(n_splits=5, random_state = seed, shuffle = True)\n",
    "    cv = np.zeros((train.shape[0], 3))\n",
    "    pred_test = np.zeros((test_x.shape[0], 3), dtype=float)\n",
    "    \n",
    "    for n, (train_idx, val_idx) in enumerate(kfold.split(train)):\n",
    "        \n",
    "        x_train, x_val = train_x.iloc[train_idx], train_x.iloc[val_idx]\n",
    "        y_train, y_val = train_y.iloc[train_idx], train_y.iloc[val_idx]\n",
    "        _train = Pool(x_train, label=y_train)\n",
    "        _valid = Pool(x_val, label=y_val)\n",
    "\n",
    "        catmodel =  CatBoostClassifier(loss_function='MultiClass', early_stopping_rounds=50, \n",
    "                                       random_state=seed, learning_rate=0.02, iterations=100000\n",
    "                                       #task_type=\"GPU\"\n",
    "                                      )\n",
    "        \n",
    "        catmodel.fit(_train, eval_set=_valid, use_best_model=True, verbose=2000)\n",
    "        #joblib.dump(rfmodel, f'./pred_pkl/RF_{n+1}_fold_{seed}_seed_rf.pkl')\n",
    "        \n",
    "        cv[val_idx, :] = catmodel.predict_proba(x_val)        \n",
    "        pred_test += catmodel.predict_proba(test_x) / 5\n",
    "        \n",
    "    pred_dict['cat'+str(i+1)] = cv\n",
    "    pred_test_dict['cat'+str(i+1)] = pred_test\n",
    "    print('multi_logloss :', log_loss(true, cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) Stacking (AutoLGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 27features = 3seed(42, 2019, 91373) x 3model(lgb, xgb, rf) x 3class(0, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(np.hstack([x for _, x in pred_dict.items()]))\n",
    "X_test = pd.DataFrame(np.hstack([x for _, x in pred_test_dict.items()]))\n",
    "\n",
    "pred = np.zeros((X_train.shape[0], 3), dtype=float)\n",
    "pred_test = np.zeros((X_test.shape[0], 3), dtype=float)\n",
    "#kfold = KFold(n_splits=5, random_state = seed, shuffle = True)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for i_cv, (i_trn, i_val) in enumerate(cv.split(X_train, train_y)):\n",
    "    if i_cv == 0:\n",
    "        clf = AutoLGB(objective='multiclass', metric='multi_logloss', params={'num_class': 3}, \n",
    "                      feature_selection=False, n_est=10000)\n",
    "        clf.tune(X_train.iloc[i_trn], train_y[i_trn])\n",
    "        n_best = clf.n_best\n",
    "        features = clf.features\n",
    "        params = clf.params\n",
    "        print(f'best iteration: {n_best}')\n",
    "        print(f'selected features ({len(features)}): {features}')        \n",
    "        print(params)\n",
    "        clf.fit(X_train.iloc[i_trn], train_y[i_trn])\n",
    "    else:\n",
    "        train_data = lgb.Dataset(X_train[features].iloc[i_trn], label=train_y[i_trn])\n",
    "        clf = lgb.train(params, train_data, n_best, verbose_eval=100)\n",
    "    \n",
    "    pred[i_val] = clf.predict(X_train[features].iloc[i_val])\n",
    "    pred_test += clf.predict(X_test[features]) / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'CV Log Loss: {log_loss(train_y, pred):.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 결과 제출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = sample_submission.copy()\n",
    "submission.iloc[:, 1:] = pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission/submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
